{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472fadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02dc0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "DATA_DIR = \"\"   # <- Directory where parquet files are stored\n",
    "WINDOW = 4320 # rolling window length (4320 = 3 days of 1-min bars set by default)\n",
    "PVAL_THRESHOLD = 0.05 # cointegration significance level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519ebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded AAVE, 525601 rows\n",
      "Loaded ADA, 525601 rows\n",
      "Loaded APT, 525601 rows\n",
      "Loaded ARB, 525601 rows\n",
      "Loaded ATOM, 525601 rows\n",
      "Loaded AVAX, 525601 rows\n",
      "Loaded BCH, 525601 rows\n",
      "Loaded BNB, 525601 rows\n",
      "Loaded BTC, 525601 rows\n",
      "Loaded DOGE, 525601 rows\n",
      "Loaded DOT, 525601 rows\n",
      "Loaded ENA, 525601 rows\n",
      "Loaded ETC, 525601 rows\n",
      "Loaded ETH, 525601 rows\n",
      "Loaded HBAR, 525601 rows\n",
      "Loaded LINK, 525601 rows\n",
      "Loaded LTC, 525601 rows\n",
      "Loaded NEAR, 525601 rows\n",
      "Loaded SOL, 525601 rows\n",
      "Loaded SUI, 525601 rows\n",
      "Loaded TON, 525601 rows\n",
      "Loaded TRX, 525601 rows\n",
      "Loaded UNI, 525601 rows\n",
      "Loaded WLD, 525601 rows\n",
      "Loaded XLM, 525601 rows\n",
      "Loaded XRP, 525601 rows\n",
      "✅ Loaded 26 full symbols\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_and_filter(folder, start=\"2024-05-01 00:00:00\", end=\"2025-05-01 00:00:00\"):\n",
    "    \"\"\"\n",
    "    Load 1-minute crypto parquet files with full data coverage,\n",
    "    filter by datetime range, and compute log prices & returns.\n",
    "    \"\"\"\n",
    "    start = pd.Timestamp(start)\n",
    "    end = pd.Timestamp(end)\n",
    "    data = {}\n",
    "\n",
    "    for f in glob.glob(os.path.join(folder, \"*_1m_bin_futures.parquet\")):\n",
    "        sym = os.path.basename(f).replace(\"_1m_bin_futures.parquet\", \"\").replace(\"USDT\", \"\")\n",
    "        df = pd.read_parquet(f)\n",
    "\n",
    "        # Convert to datetime if needed\n",
    "        if \"datetime\" in df.columns:\n",
    "            df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "        else:\n",
    "            df[\"datetime\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "\n",
    "        # Filter by the specified time window\n",
    "        df = df[(df[\"datetime\"] >= start) & (df[\"datetime\"] <= end)]\n",
    "        df = df.set_index(\"datetime\").sort_index()\n",
    "\n",
    "        # Log prices and returns\n",
    "        df[\"close\"] = np.log(df[\"close\"])\n",
    "        df[\"open\"] = np.log(df[\"open\"])\n",
    "        df[\"high\"] = np.log(df[\"high\"])\n",
    "        df[\"low\"] = np.log(df[\"low\"])\n",
    "        df[\"log_return\"] = df[\"close\"].diff()\n",
    "\n",
    "        data[sym] = df\n",
    "\n",
    "        print(f\"Loaded {sym}, {len(df)} rows\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Example usage\n",
    "crypto_data = load_and_filter(\"\", start=\"2024-05-01 00:00:00\", end=\"2025-05-01 00:00:00\")\n",
    "print(f\"✅ Loaded {len(crypto_data)} full symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cbc9cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AAVE       ADA       APT       ARB      ATOM      AVAX       BCH  \\\n",
      "AAVE  1.000000  0.795344  0.287267 -0.116136 -0.048480  0.322662  0.205828   \n",
      "ADA   0.795344  1.000000  0.265865  0.031820  0.297912  0.415695  0.451184   \n",
      "APT   0.287267  0.265865  1.000000  0.739254  0.641260  0.884179  0.798965   \n",
      "ARB  -0.116136  0.031820  0.739254  1.000000  0.899804  0.864401  0.824643   \n",
      "ATOM -0.048480  0.297912  0.641260  0.899804  1.000000  0.837609  0.880414   \n",
      "AVAX  0.322662  0.415695  0.884179  0.864401  0.837609  1.000000  0.907443   \n",
      "BCH   0.205828  0.451184  0.798965  0.824643  0.880414  0.907443  1.000000   \n",
      "BNB   0.723406  0.799381  0.544490  0.326498  0.476428  0.649551  0.637548   \n",
      "BTC   0.843573  0.946783  0.240247 -0.096592  0.138178  0.330407  0.348356   \n",
      "DOGE  0.787217  0.915396  0.539192  0.231368  0.401913  0.615882  0.603221   \n",
      "DOT   0.176746  0.455486  0.687081  0.875746  0.949446  0.899393  0.896548   \n",
      "ENA   0.335875  0.571381  0.660192  0.747169  0.850147  0.843024  0.862340   \n",
      "ETC   0.195897  0.418168  0.774295  0.910359  0.927231  0.936127  0.934524   \n",
      "ETH   0.053358  0.132654  0.721231  0.933636  0.811947  0.848221  0.780457   \n",
      "HBAR  0.724869  0.942829  0.086282 -0.005131  0.286928  0.316660  0.360786   \n",
      "LINK  0.691500  0.845060  0.461248  0.431673  0.597882  0.700454  0.680417   \n",
      "LTC   0.752028  0.903323  0.284702  0.143403  0.348727  0.452507  0.445228   \n",
      "NEAR -0.135815 -0.049886  0.787016  0.970667  0.827079  0.849837  0.780260   \n",
      "SOL   0.594401  0.596563  0.723644  0.507026  0.495232  0.782588  0.704385   \n",
      "SUI   0.909536  0.851944  0.345545 -0.141644  0.006154  0.327223  0.263110   \n",
      "TON  -0.375069 -0.339114  0.519266  0.833211  0.649366  0.580386  0.519066   \n",
      "TRX   0.874583  0.838706  0.037014 -0.389562 -0.172028  0.066411  0.043486   \n",
      "UNI   0.562932  0.597058  0.723544  0.686768  0.685920  0.861937  0.772847   \n",
      "WLD  -0.262385 -0.124860  0.711847  0.955740  0.839757  0.783399  0.757988   \n",
      "XLM   0.833041  0.972231  0.146234 -0.116032  0.149857  0.286222  0.297668   \n",
      "XRP   0.823317  0.909948 -0.066352 -0.332274 -0.060371  0.065462  0.088817   \n",
      "\n",
      "           BNB       BTC      DOGE  ...       LTC      NEAR       SOL  \\\n",
      "AAVE  0.723406  0.843573  0.787217  ...  0.752028 -0.135815  0.594401   \n",
      "ADA   0.799381  0.946783  0.915396  ...  0.903323 -0.049886  0.596563   \n",
      "APT   0.544490  0.240247  0.539192  ...  0.284702  0.787016  0.723644   \n",
      "ARB   0.326498 -0.096592  0.231368  ...  0.143403  0.970667  0.507026   \n",
      "ATOM  0.476428  0.138178  0.401913  ...  0.348727  0.827079  0.495232   \n",
      "AVAX  0.649551  0.330407  0.615882  ...  0.452507  0.849837  0.782588   \n",
      "BCH   0.637548  0.348356  0.603221  ...  0.445228  0.780260  0.704385   \n",
      "BNB   1.000000  0.809975  0.845938  ...  0.818476  0.270901  0.691826   \n",
      "BTC   0.809975  1.000000  0.916603  ...  0.881099 -0.158265  0.629298   \n",
      "DOGE  0.845938  0.916603  1.000000  ...  0.861058  0.177665  0.807153   \n",
      "DOT   0.583449  0.290449  0.555009  ...  0.496161  0.803889  0.638827   \n",
      "ENA   0.740131  0.488551  0.687004  ...  0.631244  0.654446  0.659848   \n",
      "ETC   0.600102  0.292498  0.572322  ...  0.493784  0.856640  0.710481   \n",
      "ETH   0.412260  0.050077  0.353892  ...  0.258114  0.901004  0.646962   \n",
      "HBAR  0.747321  0.887484  0.799963  ...  0.910465 -0.122221  0.442103   \n",
      "LINK  0.861044  0.794374  0.853105  ...  0.881316  0.330973  0.731129   \n",
      "LTC   0.818476  0.881099  0.861058  ...  1.000000  0.050957  0.607702   \n",
      "NEAR  0.270901 -0.158265  0.177665  ...  0.050957  1.000000  0.515057   \n",
      "SOL   0.691826  0.629298  0.807153  ...  0.607702  0.515057  1.000000   \n",
      "SUI   0.769852  0.921960  0.863169  ...  0.777983 -0.159452  0.584600   \n",
      "TON  -0.022291 -0.444023 -0.140088  ... -0.274371  0.851429  0.259111   \n",
      "TRX   0.613254  0.872189  0.721410  ...  0.721104 -0.425041  0.365580   \n",
      "UNI   0.779863  0.541591  0.745859  ...  0.664408  0.616053  0.786135   \n",
      "WLD   0.215390 -0.216786  0.102498  ...  0.011286  0.952601  0.403119   \n",
      "XLM   0.734789  0.945262  0.863877  ...  0.876738 -0.196796  0.525183   \n",
      "XRP   0.643914  0.916262  0.745282  ...  0.824519 -0.409918  0.361689   \n",
      "\n",
      "           SUI       TON       TRX       UNI       WLD       XLM       XRP  \n",
      "AAVE  0.909536 -0.375069  0.874583  0.562932 -0.262385  0.833041  0.823317  \n",
      "ADA   0.851944 -0.339114  0.838706  0.597058 -0.124860  0.972231  0.909948  \n",
      "APT   0.345545  0.519266  0.037014  0.723544  0.711847  0.146234 -0.066352  \n",
      "ARB  -0.141644  0.833211 -0.389562  0.686768  0.955740 -0.116032 -0.332274  \n",
      "ATOM  0.006154  0.649366 -0.172028  0.685920  0.839757  0.149857 -0.060371  \n",
      "AVAX  0.327223  0.580386  0.066411  0.861937  0.783399  0.286222  0.065462  \n",
      "BCH   0.263110  0.519066  0.043486  0.772847  0.757988  0.297668  0.088817  \n",
      "BNB   0.769852 -0.022291  0.613254  0.779863  0.215390  0.734789  0.643914  \n",
      "BTC   0.921960 -0.444023  0.872189  0.541591 -0.216786  0.945262  0.916262  \n",
      "DOGE  0.863169 -0.140088  0.721410  0.745859  0.102498  0.863877  0.745282  \n",
      "DOT   0.171034  0.610601  0.010106  0.824741  0.756134  0.320621  0.101461  \n",
      "ENA   0.395629  0.375160  0.153497  0.850413  0.673386  0.438872  0.268823  \n",
      "ETC   0.195253  0.609790 -0.027663  0.845450  0.814167  0.271764  0.054826  \n",
      "ETH  -0.027158  0.803366 -0.266275  0.800654  0.841974 -0.003906 -0.207547  \n",
      "HBAR  0.763923 -0.393255  0.788036  0.532939 -0.142154  0.935226  0.915868  \n",
      "LINK  0.669701  0.044009  0.560851  0.853234  0.277566  0.772747  0.667001  \n",
      "LTC   0.777983 -0.274371  0.721104  0.664408  0.011286  0.876738  0.824519  \n",
      "NEAR -0.159452  0.851429 -0.425041  0.616053  0.952601 -0.196796 -0.409918  \n",
      "SOL   0.584600  0.259111  0.365580  0.786135  0.403119  0.525183  0.361689  \n",
      "SUI   1.000000 -0.465791  0.885406  0.507753 -0.231810  0.868318  0.841104  \n",
      "TON  -0.465791  1.000000 -0.622484  0.411369  0.805459 -0.445998 -0.621224  \n",
      "TRX   0.885406 -0.622484  1.000000  0.299045 -0.513631  0.897510  0.933901  \n",
      "UNI   0.507753  0.411369  0.299045  1.000000  0.533574  0.506691  0.330410  \n",
      "WLD  -0.231810  0.805459 -0.513631  0.533574  1.000000 -0.272772 -0.469707  \n",
      "XLM   0.868318 -0.445998  0.897510  0.506691 -0.272772  1.000000  0.961409  \n",
      "XRP   0.841104 -0.621224  0.933901  0.330410 -0.469707  0.961409  1.000000  \n",
      "\n",
      "[26 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# first round selection based on correlation (whole period)\n",
    "# correlation matrix\n",
    "def compute_correlation_matrix(crypto_data):\n",
    "    \"\"\"\n",
    "    Compute correlation matrix of closing prices for all cryptos.\n",
    "    Returns a DataFrame with symbols as both index and columns.\n",
    "    \"\"\"\n",
    "    symbols = list(crypto_data.keys())\n",
    "    close_prices = pd.DataFrame({sym: crypto_data[sym][\"close\"] for sym in symbols})\n",
    "    corr_matrix = close_prices.corr()\n",
    "    return corr_matrix\n",
    "correlation_matrix = compute_correlation_matrix(crypto_data)\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c77900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High correlation: AAVE & SUI = 0.91\n",
      "High correlation: AAVE & TRX = 0.87\n",
      "High correlation: ADA & BTC = 0.95\n",
      "High correlation: ADA & DOGE = 0.92\n",
      "High correlation: ADA & HBAR = 0.94\n",
      "High correlation: ADA & LTC = 0.90\n",
      "High correlation: ADA & SUI = 0.85\n",
      "High correlation: ADA & XLM = 0.97\n",
      "High correlation: ADA & XRP = 0.91\n",
      "High correlation: APT & AVAX = 0.88\n",
      "High correlation: ARB & ATOM = 0.90\n",
      "High correlation: ARB & AVAX = 0.86\n",
      "High correlation: ARB & DOT = 0.88\n",
      "High correlation: ARB & ETC = 0.91\n",
      "High correlation: ARB & ETH = 0.93\n",
      "High correlation: ARB & NEAR = 0.97\n",
      "High correlation: ARB & WLD = 0.96\n",
      "High correlation: ATOM & BCH = 0.88\n",
      "High correlation: ATOM & DOT = 0.95\n",
      "High correlation: ATOM & ENA = 0.85\n",
      "High correlation: ATOM & ETC = 0.93\n",
      "High correlation: AVAX & BCH = 0.91\n",
      "High correlation: AVAX & DOT = 0.90\n",
      "High correlation: AVAX & ETC = 0.94\n",
      "High correlation: AVAX & UNI = 0.86\n",
      "High correlation: BCH & DOT = 0.90\n",
      "High correlation: BCH & ENA = 0.86\n",
      "High correlation: BCH & ETC = 0.93\n",
      "High correlation: BNB & LINK = 0.86\n",
      "High correlation: BTC & DOGE = 0.92\n",
      "High correlation: BTC & HBAR = 0.89\n",
      "High correlation: BTC & LTC = 0.88\n",
      "High correlation: BTC & SUI = 0.92\n",
      "High correlation: BTC & TRX = 0.87\n",
      "High correlation: BTC & XLM = 0.95\n",
      "High correlation: BTC & XRP = 0.92\n",
      "High correlation: DOGE & LINK = 0.85\n",
      "High correlation: DOGE & LTC = 0.86\n",
      "High correlation: DOGE & SUI = 0.86\n",
      "High correlation: DOGE & XLM = 0.86\n",
      "High correlation: DOT & ENA = 0.87\n",
      "High correlation: DOT & ETC = 0.96\n",
      "High correlation: DOT & ETH = 0.86\n",
      "High correlation: ENA & ETC = 0.89\n",
      "High correlation: ENA & UNI = 0.85\n",
      "High correlation: ETC & ETH = 0.90\n",
      "High correlation: ETC & NEAR = 0.86\n",
      "High correlation: ETH & NEAR = 0.90\n",
      "High correlation: HBAR & LTC = 0.91\n",
      "High correlation: HBAR & XLM = 0.94\n",
      "High correlation: HBAR & XRP = 0.92\n",
      "High correlation: LINK & LTC = 0.88\n",
      "High correlation: LINK & UNI = 0.85\n",
      "High correlation: LTC & XLM = 0.88\n",
      "High correlation: NEAR & TON = 0.85\n",
      "High correlation: NEAR & WLD = 0.95\n",
      "High correlation: SUI & TRX = 0.89\n",
      "High correlation: SUI & XLM = 0.87\n",
      "High correlation: TRX & XLM = 0.90\n",
      "High correlation: TRX & XRP = 0.93\n",
      "High correlation: XLM & XRP = 0.96\n"
     ]
    }
   ],
   "source": [
    "# select those with correlation > 0.85\n",
    "high_corr_pairs = []\n",
    "threshold = 0.85\n",
    "symbols = list(crypto_data.keys())\n",
    "for i in range(len(symbols)):\n",
    "    for j in range(i+1, len(symbols)):\n",
    "        sym1, sym2 = symbols[i], symbols[j]\n",
    "        corr = correlation_matrix.loc[sym1, sym2]\n",
    "        if abs(corr) > threshold:\n",
    "            high_corr_pairs.append((sym1, sym2))\n",
    "            print(f\"High correlation: {sym1} & {sym2} = {corr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4193ed78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(high_corr_pairs)  # number of high correlation pairs found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0636b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rolling_cointegration(y, x, window=4320, adf_pval=0.05):\n",
    "    \"\"\"\n",
    "    Rolling Engle–Granger cointegration test with beta estimation.\n",
    "    Returns DataFrame with beta, ADF p-value, and spread.\n",
    "    \"\"\"\n",
    "    y, x = y.align(x, join=\"inner\")\n",
    "    y, x = y.sort_index(), x.sort_index()\n",
    "\n",
    "    results = []\n",
    "    step = window // 3  # overlap control\n",
    "    timestamps = y.index\n",
    "\n",
    "    for i in range(0, len(timestamps) - window, step):\n",
    "        start_time = timestamps[i]\n",
    "        end_time = timestamps[i + window - 1]\n",
    "\n",
    "        y_win = y.loc[start_time:end_time]\n",
    "        x_win = x.loc[start_time:end_time]\n",
    "\n",
    "        if len(y_win) < window or y_win.isna().any() or x_win.isna().any():\n",
    "            continue\n",
    "\n",
    "        model = OLS(y_win, add_constant(x_win)).fit()\n",
    "        alpha, beta = model.params\n",
    "\n",
    "        residuals = y_win - model.predict(add_constant(x_win))\n",
    "        adf_p = adfuller(residuals)[1]\n",
    "        corr = y_win.corr(x_win)\n",
    "\n",
    "        results.append({\n",
    "            \"start\": start_time,\n",
    "            \"end\": end_time,\n",
    "            \"alpha\": alpha,\n",
    "            \"beta\": beta,\n",
    "            \"adf_p\": adf_p,\n",
    "            \"cointegrated\": adf_p <= adf_pval,\n",
    "            \"correlation\": corr\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123235cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_pairs(crypto_data, list_of_pairs, window=4320, adf_pval=0.05):\n",
    "    \"\"\"\n",
    "    Iterate through crypto pairs, compute rolling cointegration + correlation,\n",
    "    and generate RL features.\n",
    "    Returns: dict { (sym1, sym2): features_df }\n",
    "    \"\"\"\n",
    "    pair_df = {}\n",
    "    i = 1\n",
    "    for sym1, sym2 in list_of_pairs:\n",
    "        print(f\"Processing pair: {sym1}, {sym2}. {i} of {len(list_of_pairs)}\")\n",
    "        i += 1\n",
    "        y_ohlc = crypto_data[sym1]\n",
    "        x_ohlc = crypto_data[sym2]\n",
    "\n",
    "        # align close prices for cointegration\n",
    "        df_close = pd.concat([y_ohlc[\"close\"], x_ohlc[\"close\"]], axis=1, join=\"inner\").dropna()\n",
    "        y_aligned, x_aligned = df_close.iloc[:, 0], df_close.iloc[:, 1]\n",
    "\n",
    "        # Rolling-window Engle–Granger test\n",
    "        coint_df = rolling_cointegration(y_aligned, x_aligned, window=window,\n",
    "                                        adf_pval=adf_pval)\n",
    "        pair_df[(sym1, sym2)] = coint_df\n",
    "\n",
    "    return pair_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56eecbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: AAVE, SUI. 1 of 61\n",
      "Processing pair: AAVE, TRX. 2 of 61\n",
      "Processing pair: ADA, BTC. 3 of 61\n",
      "Processing pair: ADA, DOGE. 4 of 61\n",
      "Processing pair: ADA, HBAR. 5 of 61\n",
      "Processing pair: ADA, LTC. 6 of 61\n",
      "Processing pair: ADA, SUI. 7 of 61\n",
      "Processing pair: ADA, XLM. 8 of 61\n",
      "Processing pair: ADA, XRP. 9 of 61\n",
      "Processing pair: APT, AVAX. 10 of 61\n",
      "Processing pair: ARB, ATOM. 11 of 61\n",
      "Processing pair: ARB, AVAX. 12 of 61\n",
      "Processing pair: ARB, DOT. 13 of 61\n",
      "Processing pair: ARB, ETC. 14 of 61\n",
      "Processing pair: ARB, ETH. 15 of 61\n",
      "Processing pair: ARB, NEAR. 16 of 61\n",
      "Processing pair: ARB, WLD. 17 of 61\n",
      "Processing pair: ATOM, BCH. 18 of 61\n",
      "Processing pair: ATOM, DOT. 19 of 61\n",
      "Processing pair: ATOM, ENA. 20 of 61\n",
      "Processing pair: ATOM, ETC. 21 of 61\n",
      "Processing pair: AVAX, BCH. 22 of 61\n",
      "Processing pair: AVAX, DOT. 23 of 61\n",
      "Processing pair: AVAX, ETC. 24 of 61\n",
      "Processing pair: AVAX, UNI. 25 of 61\n",
      "Processing pair: BCH, DOT. 26 of 61\n",
      "Processing pair: BCH, ENA. 27 of 61\n",
      "Processing pair: BCH, ETC. 28 of 61\n",
      "Processing pair: BNB, LINK. 29 of 61\n",
      "Processing pair: BTC, DOGE. 30 of 61\n",
      "Processing pair: BTC, HBAR. 31 of 61\n",
      "Processing pair: BTC, LTC. 32 of 61\n",
      "Processing pair: BTC, SUI. 33 of 61\n",
      "Processing pair: BTC, TRX. 34 of 61\n",
      "Processing pair: BTC, XLM. 35 of 61\n",
      "Processing pair: BTC, XRP. 36 of 61\n",
      "Processing pair: DOGE, LINK. 37 of 61\n",
      "Processing pair: DOGE, LTC. 38 of 61\n",
      "Processing pair: DOGE, SUI. 39 of 61\n",
      "Processing pair: DOGE, XLM. 40 of 61\n",
      "Processing pair: DOT, ENA. 41 of 61\n",
      "Processing pair: DOT, ETC. 42 of 61\n",
      "Processing pair: DOT, ETH. 43 of 61\n",
      "Processing pair: ENA, ETC. 44 of 61\n",
      "Processing pair: ENA, UNI. 45 of 61\n",
      "Processing pair: ETC, ETH. 46 of 61\n",
      "Processing pair: ETC, NEAR. 47 of 61\n",
      "Processing pair: ETH, NEAR. 48 of 61\n",
      "Processing pair: HBAR, LTC. 49 of 61\n",
      "Processing pair: HBAR, XLM. 50 of 61\n",
      "Processing pair: HBAR, XRP. 51 of 61\n",
      "Processing pair: LINK, LTC. 52 of 61\n",
      "Processing pair: LINK, UNI. 53 of 61\n",
      "Processing pair: LTC, XLM. 54 of 61\n",
      "Processing pair: NEAR, TON. 55 of 61\n",
      "Processing pair: NEAR, WLD. 56 of 61\n",
      "Processing pair: SUI, TRX. 57 of 61\n",
      "Processing pair: SUI, XLM. 58 of 61\n",
      "Processing pair: TRX, XLM. 59 of 61\n",
      "Processing pair: TRX, XRP. 60 of 61\n",
      "Processing pair: XLM, XRP. 61 of 61\n"
     ]
    }
   ],
   "source": [
    "coint_df = prepare_all_pairs(crypto_data, high_corr_pairs, window=WINDOW,\n",
    "                             adf_pval=PVAL_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c49d5fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features for pair AAVE-SUI to AAVE_SUI_bin_futures_window_cointegration.csv\n",
      "Saved features for pair AAVE-TRX to AAVE_TRX_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ADA-BTC to ADA_BTC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ADA-DOGE to ADA_DOGE_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ADA-HBAR to ADA_HBAR_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ADA-LTC to ADA_LTC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ADA-SUI to ADA_SUI_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ADA-XLM to ADA_XLM_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ADA-XRP to ADA_XRP_bin_futures_window_cointegration.csv\n",
      "Saved features for pair APT-AVAX to APT_AVAX_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ARB-ATOM to ARB_ATOM_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ARB-AVAX to ARB_AVAX_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ARB-DOT to ARB_DOT_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ARB-ETC to ARB_ETC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ARB-ETH to ARB_ETH_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ARB-NEAR to ARB_NEAR_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ARB-WLD to ARB_WLD_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ATOM-BCH to ATOM_BCH_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ATOM-DOT to ATOM_DOT_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ATOM-ENA to ATOM_ENA_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ATOM-ETC to ATOM_ETC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair AVAX-BCH to AVAX_BCH_bin_futures_window_cointegration.csv\n",
      "Saved features for pair AVAX-DOT to AVAX_DOT_bin_futures_window_cointegration.csv\n",
      "Saved features for pair AVAX-ETC to AVAX_ETC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair AVAX-UNI to AVAX_UNI_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BCH-DOT to BCH_DOT_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BCH-ENA to BCH_ENA_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BCH-ETC to BCH_ETC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BNB-LINK to BNB_LINK_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BTC-DOGE to BTC_DOGE_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BTC-HBAR to BTC_HBAR_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BTC-LTC to BTC_LTC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BTC-SUI to BTC_SUI_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BTC-TRX to BTC_TRX_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BTC-XLM to BTC_XLM_bin_futures_window_cointegration.csv\n",
      "Saved features for pair BTC-XRP to BTC_XRP_bin_futures_window_cointegration.csv\n",
      "Saved features for pair DOGE-LINK to DOGE_LINK_bin_futures_window_cointegration.csv\n",
      "Saved features for pair DOGE-LTC to DOGE_LTC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair DOGE-SUI to DOGE_SUI_bin_futures_window_cointegration.csv\n",
      "Saved features for pair DOGE-XLM to DOGE_XLM_bin_futures_window_cointegration.csv\n",
      "Saved features for pair DOT-ENA to DOT_ENA_bin_futures_window_cointegration.csv\n",
      "Saved features for pair DOT-ETC to DOT_ETC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair DOT-ETH to DOT_ETH_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ENA-ETC to ENA_ETC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ENA-UNI to ENA_UNI_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ETC-ETH to ETC_ETH_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ETC-NEAR to ETC_NEAR_bin_futures_window_cointegration.csv\n",
      "Saved features for pair ETH-NEAR to ETH_NEAR_bin_futures_window_cointegration.csv\n",
      "Saved features for pair HBAR-LTC to HBAR_LTC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair HBAR-XLM to HBAR_XLM_bin_futures_window_cointegration.csv\n",
      "Saved features for pair HBAR-XRP to HBAR_XRP_bin_futures_window_cointegration.csv\n",
      "Saved features for pair LINK-LTC to LINK_LTC_bin_futures_window_cointegration.csv\n",
      "Saved features for pair LINK-UNI to LINK_UNI_bin_futures_window_cointegration.csv\n",
      "Saved features for pair LTC-XLM to LTC_XLM_bin_futures_window_cointegration.csv\n",
      "Saved features for pair NEAR-TON to NEAR_TON_bin_futures_window_cointegration.csv\n",
      "Saved features for pair NEAR-WLD to NEAR_WLD_bin_futures_window_cointegration.csv\n",
      "Saved features for pair SUI-TRX to SUI_TRX_bin_futures_window_cointegration.csv\n",
      "Saved features for pair SUI-XLM to SUI_XLM_bin_futures_window_cointegration.csv\n",
      "Saved features for pair TRX-XLM to TRX_XLM_bin_futures_window_cointegration.csv\n",
      "Saved features for pair TRX-XRP to TRX_XRP_bin_futures_window_cointegration.csv\n",
      "Saved features for pair XLM-XRP to XLM_XRP_bin_futures_window_cointegration.csv\n"
     ]
    }
   ],
   "source": [
    "#save dictionary into csv\n",
    "for (sym1, sym2), df in coint_df.items():\n",
    "    filename = f\"{sym1}_{sym2}_bin_futures_window_cointegration.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved features for pair {sym1}-{sym2} to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33581ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of top-5 pairs per window based on correlation\n",
    "top_pairs_per_window = {}\n",
    "for pair, df in coint_df.items():\n",
    "    for _, row in df.iterrows():\n",
    "        window_key = (row[\"start\"], row[\"end\"])\n",
    "        if window_key not in top_pairs_per_window:\n",
    "            top_pairs_per_window[window_key] = []\n",
    "        if row[\"cointegrated\"]:\n",
    "            top_pairs_per_window[window_key].append((pair, row[\"correlation\"], row[\"beta\"], row[\"alpha\"], row[\"adf_p\"]))\n",
    "# keep top 5 pairs by correlation for each window\n",
    "for window_key, pairs in top_pairs_per_window.items():\n",
    "    # sort by absolute correlation\n",
    "    pairs.sort(key=lambda x: abs(x[1]), reverse=True)  \n",
    "    top_pairs_per_window[window_key] = pairs[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3dfca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only 4 pairs found for window (Timestamp('2024-05-05 00:00:00'), Timestamp('2024-05-07 23:59:00'))\n",
      "Warning: Only 2 pairs found for window (Timestamp('2024-05-11 00:00:00'), Timestamp('2024-05-13 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2024-06-27 00:00:00'), Timestamp('2024-06-29 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2024-06-28 00:00:00'), Timestamp('2024-06-30 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2024-07-24 00:00:00'), Timestamp('2024-07-26 23:59:00'))\n",
      "Warning: Only 1 pairs found for window (Timestamp('2024-08-11 00:00:00'), Timestamp('2024-08-13 23:59:00'))\n",
      "Warning: Only 3 pairs found for window (Timestamp('2024-08-17 00:00:00'), Timestamp('2024-08-19 23:59:00'))\n",
      "Warning: Only 0 pairs found for window (Timestamp('2024-08-18 00:00:00'), Timestamp('2024-08-20 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2024-09-13 00:00:00'), Timestamp('2024-09-15 23:59:00'))\n",
      "Warning: Only 2 pairs found for window (Timestamp('2025-01-01 00:00:00'), Timestamp('2025-01-03 23:59:00'))\n",
      "Warning: Only 2 pairs found for window (Timestamp('2025-02-19 00:00:00'), Timestamp('2025-02-21 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2025-02-26 00:00:00'), Timestamp('2025-02-28 23:59:00'))\n",
      "Warning: Only 2 pairs found for window (Timestamp('2025-02-27 00:00:00'), Timestamp('2025-03-01 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2025-04-06 00:00:00'), Timestamp('2025-04-08 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2025-04-20 00:00:00'), Timestamp('2025-04-22 23:59:00'))\n"
     ]
    }
   ],
   "source": [
    "# make sure that there are 5 pairs for each window\n",
    "for window_key, pairs in top_pairs_per_window.items():\n",
    "    if len(pairs) < 5:\n",
    "        print(f\"Warning: Only {len(pairs)} pairs found for window {window_key}\")\n",
    "# not always 5 pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d448f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate how many times each pair appears in top-5 across all windows\n",
    "from collections import Counter\n",
    "pair_counter = Counter()\n",
    "for pairs in top_pairs_per_window.values():\n",
    "    for pair_info in pairs:\n",
    "        pair = pair_info[0]\n",
    "        pair_counter[pair] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18403ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair_counter)\n",
    "# each pair occurs at least once in top-5 across all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f2292c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "336/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b182a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (('ARB', 'ETC'), 60),\n",
    "    (('NEAR', 'WLD'), 56),\n",
    "    (('DOT', 'ETC'), 55),\n",
    "    (('AVAX', 'DOT'), 54),\n",
    "    (('ADA', 'HBAR'), 54),\n",
    "    (('BTC', 'DOGE'), 53),\n",
    "    (('BCH', 'ETC'), 51),\n",
    "    (('ARB', 'WLD'), 50),\n",
    "    (('ETC', 'NEAR'), 46),\n",
    "    (('HBAR', 'XLM'), 45),\n",
    "    (('ETC', 'ETH'), 44),\n",
    "    (('ARB', 'NEAR'), 43),\n",
    "    (('ATOM', 'DOT'), 42),\n",
    "    (('DOGE', 'LINK'), 41),\n",
    "    (('ATOM', 'ETC'), 41),\n",
    "    (('XLM', 'XRP'), 40),\n",
    "    (('ARB', 'DOT'), 39),\n",
    "    (('AVAX', 'ETC'), 38),\n",
    "    (('ARB', 'ETH'), 37),\n",
    "    (('ARB', 'AVAX'), 36),\n",
    "    (('ADA', 'XRP'), 35),\n",
    "    (('APT', 'AVAX'), 35),\n",
    "    (('ADA', 'DOGE'), 34),\n",
    "    (('ARB', 'ATOM'), 32),\n",
    "    (('ADA', 'LTC'), 31),\n",
    "    (('HBAR', 'XRP'), 31),\n",
    "    (('ADA', 'XLM'), 30),\n",
    "    (('AVAX', 'BCH'), 27),\n",
    "    (('DOGE', 'LTC'), 27),\n",
    "    (('ADA', 'BTC'), 27),\n",
    "    (('BNB', 'LINK'), 26),\n",
    "    (('BTC', 'XRP'), 26),\n",
    "    (('DOGE', 'XLM'), 25),\n",
    "    (('AVAX', 'UNI'), 25),\n",
    "    (('LINK', 'UNI'), 24),\n",
    "    (('ATOM', 'BCH'), 23),\n",
    "    (('LINK', 'LTC'), 23),\n",
    "    (('LTC', 'XLM'), 22),\n",
    "    (('ADA', 'SUI'), 22),\n",
    "    (('BCH', 'DOT'), 22),\n",
    "    (('ENA', 'UNI'), 22),\n",
    "    (('BCH', 'ENA'), 21),\n",
    "    (('ENA', 'ETC'), 21),\n",
    "    (('DOT', 'ETH'), 20),\n",
    "    (('AAVE', 'SUI'), 19),\n",
    "    (('DOT', 'ENA'), 19),\n",
    "    (('BTC', 'HBAR'), 19),\n",
    "    (('BTC', 'SUI'), 18),\n",
    "    (('BTC', 'XLM'), 18),\n",
    "    (('DOGE', 'SUI'), 17),\n",
    "    (('ETH', 'NEAR'), 16),\n",
    "    (('HBAR', 'LTC'), 16),\n",
    "    (('SUI', 'XLM'), 15),\n",
    "    (('ATOM', 'ENA'), 15),\n",
    "    (('BTC', 'LTC'), 14),\n",
    "    (('TRX', 'XRP'), 9),\n",
    "    (('BTC', 'TRX'), 8),\n",
    "    (('SUI', 'TRX'), 7),\n",
    "    (('TRX', 'XLM'), 7),\n",
    "    (('AAVE', 'TRX'), 6),\n",
    "    (('NEAR', 'TON'), 5)\n",
    "]\n",
    "\n",
    "total_sum = sum(value for _, value in data)\n",
    "print(total_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3660b183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2448000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1700*1440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53b0b0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ARB', 'ETC'), 60),\n",
       " (('NEAR', 'WLD'), 56),\n",
       " (('DOT', 'ETC'), 55),\n",
       " (('AVAX', 'DOT'), 54),\n",
       " (('ADA', 'HBAR'), 54),\n",
       " (('BTC', 'DOGE'), 53),\n",
       " (('BCH', 'ETC'), 51),\n",
       " (('ARB', 'WLD'), 50),\n",
       " (('ETC', 'NEAR'), 46),\n",
       " (('HBAR', 'XLM'), 45),\n",
       " (('ETC', 'ETH'), 44),\n",
       " (('ARB', 'NEAR'), 43),\n",
       " (('ATOM', 'DOT'), 42),\n",
       " (('DOGE', 'LINK'), 41),\n",
       " (('ATOM', 'ETC'), 41),\n",
       " (('XLM', 'XRP'), 40),\n",
       " (('ARB', 'DOT'), 39),\n",
       " (('AVAX', 'ETC'), 38),\n",
       " (('ARB', 'ETH'), 37),\n",
       " (('ARB', 'AVAX'), 36),\n",
       " (('ADA', 'XRP'), 35),\n",
       " (('APT', 'AVAX'), 35),\n",
       " (('ADA', 'DOGE'), 34),\n",
       " (('ARB', 'ATOM'), 32),\n",
       " (('ADA', 'LTC'), 31),\n",
       " (('HBAR', 'XRP'), 31),\n",
       " (('ADA', 'XLM'), 30),\n",
       " (('AVAX', 'BCH'), 27),\n",
       " (('DOGE', 'LTC'), 27),\n",
       " (('ADA', 'BTC'), 27),\n",
       " (('BNB', 'LINK'), 26),\n",
       " (('BTC', 'XRP'), 26),\n",
       " (('DOGE', 'XLM'), 25),\n",
       " (('AVAX', 'UNI'), 25),\n",
       " (('LINK', 'UNI'), 24),\n",
       " (('ATOM', 'BCH'), 23),\n",
       " (('LINK', 'LTC'), 23),\n",
       " (('LTC', 'XLM'), 22),\n",
       " (('ADA', 'SUI'), 22),\n",
       " (('BCH', 'DOT'), 22),\n",
       " (('ENA', 'UNI'), 22),\n",
       " (('BCH', 'ENA'), 21),\n",
       " (('ENA', 'ETC'), 21),\n",
       " (('DOT', 'ETH'), 20),\n",
       " (('AAVE', 'SUI'), 19),\n",
       " (('DOT', 'ENA'), 19),\n",
       " (('BTC', 'HBAR'), 19),\n",
       " (('BTC', 'SUI'), 18),\n",
       " (('BTC', 'XLM'), 18),\n",
       " (('DOGE', 'SUI'), 17),\n",
       " (('ETH', 'NEAR'), 16),\n",
       " (('HBAR', 'LTC'), 16),\n",
       " (('SUI', 'XLM'), 15),\n",
       " (('ATOM', 'ENA'), 15),\n",
       " (('BTC', 'LTC'), 14),\n",
       " (('TRX', 'XRP'), 9),\n",
       " (('BTC', 'TRX'), 8),\n",
       " (('SUI', 'TRX'), 7),\n",
       " (('TRX', 'XLM'), 7),\n",
       " (('AAVE', 'TRX'), 6),\n",
       " (('NEAR', 'TON'), 5)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_counter.most_common() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa366d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calulcate how many unique crypto assets are involved in top pairs\n",
    "unique_assets = set()\n",
    "for pair in pair_counter.keys():\n",
    "    unique_assets.update(pair)\n",
    "len(unique_assets)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93902aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def build_full_features(crypto_data, top_pairs_per_window):\n",
    "    # 1️⃣ Collect all unique symbols\n",
    "    all_symbols = sorted({\n",
    "        sym\n",
    "        for pairs in top_pairs_per_window.values()\n",
    "        for pair_info in pairs\n",
    "        for sym in pair_info[0]\n",
    "    })\n",
    "\n",
    "    # 2️⃣ Initialize base DataFrame (timestamp index)\n",
    "    full_df = pd.DataFrame(index=crypto_data[\"BTC\"].index)\n",
    "    full_df.index.name = \"timestamp\"\n",
    "\n",
    "    # 3️⃣ Add log-price columns for each symbol\n",
    "    for sym in all_symbols:\n",
    "        df = crypto_data[sym][[\"close\"]].rename(columns={\"close\": f\"{sym}_close\"})\n",
    "        full_df = full_df.join(df, how=\"left\")\n",
    "\n",
    "    # 4️⃣ For each window and cointegrated pair, compute spreads and related stats\n",
    "    for (start, end), pairs in top_pairs_per_window.items():\n",
    "        mask = (full_df.index >= start) & (full_df.index <= end)\n",
    "\n",
    "        for pair_info in pairs:\n",
    "            (sym1, sym2), corr, beta, alpha, adf_p = pair_info\n",
    "\n",
    "            spread_col = f\"{sym1}_{sym2}_spread\"\n",
    "            beta_col = f\"{sym1}_{sym2}_beta\"\n",
    "            alpha_col = f\"{sym1}_{sym2}_alpha\"\n",
    "            adf_col = f\"{sym1}_{sym2}_adf_p\"\n",
    "            corr_col = f\"{sym1}_{sym2}_corr\"\n",
    "\n",
    "            # Initialize columns if they don't exist\n",
    "            for col in [spread_col, beta_col, alpha_col, adf_col, corr_col]:\n",
    "                if col not in full_df.columns:\n",
    "                    full_df[col] = np.nan\n",
    "\n",
    "            y = full_df.loc[mask, f\"{sym1}_close\"]\n",
    "            x = full_df.loc[mask, f\"{sym2}_close\"]\n",
    "\n",
    "            full_df.loc[mask, spread_col] = y - (alpha + beta * x)\n",
    "            full_df.loc[mask, beta_col] = beta\n",
    "            full_df.loc[mask, alpha_col] = alpha\n",
    "            full_df.loc[mask, adf_col] = adf_p\n",
    "            full_df.loc[mask, corr_col] = corr\n",
    "\n",
    "    return full_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8820d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n",
      "C:\\Users\\isaen\\AppData\\Local\\Temp\\ipykernel_16112\\3320542252.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full_df[col] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525601, 330)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAVE_close</th>\n",
       "      <th>ADA_close</th>\n",
       "      <th>APT_close</th>\n",
       "      <th>ARB_close</th>\n",
       "      <th>ATOM_close</th>\n",
       "      <th>AVAX_close</th>\n",
       "      <th>BCH_close</th>\n",
       "      <th>BNB_close</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>DOGE_close</th>\n",
       "      <th>...</th>\n",
       "      <th>TRX_XRP_spread</th>\n",
       "      <th>TRX_XRP_beta</th>\n",
       "      <th>TRX_XRP_alpha</th>\n",
       "      <th>TRX_XRP_adf_p</th>\n",
       "      <th>TRX_XRP_corr</th>\n",
       "      <th>BTC_TRX_spread</th>\n",
       "      <th>BTC_TRX_beta</th>\n",
       "      <th>BTC_TRX_alpha</th>\n",
       "      <th>BTC_TRX_adf_p</th>\n",
       "      <th>BTC_TRX_corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-01 00:00:00</th>\n",
       "      <td>4.423169</td>\n",
       "      <td>-0.818257</td>\n",
       "      <td>2.166078</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>2.136176</td>\n",
       "      <td>3.486794</td>\n",
       "      <td>6.072814</td>\n",
       "      <td>6.358864</td>\n",
       "      <td>11.013869</td>\n",
       "      <td>-2.014703</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 00:01:00</th>\n",
       "      <td>4.422809</td>\n",
       "      <td>-0.819164</td>\n",
       "      <td>2.164012</td>\n",
       "      <td>0.020195</td>\n",
       "      <td>2.138418</td>\n",
       "      <td>3.485937</td>\n",
       "      <td>6.071938</td>\n",
       "      <td>6.357825</td>\n",
       "      <td>11.014249</td>\n",
       "      <td>-2.014703</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 00:02:00</th>\n",
       "      <td>4.421368</td>\n",
       "      <td>-0.819845</td>\n",
       "      <td>2.163553</td>\n",
       "      <td>0.018527</td>\n",
       "      <td>2.136294</td>\n",
       "      <td>3.485630</td>\n",
       "      <td>6.070992</td>\n",
       "      <td>6.357634</td>\n",
       "      <td>11.012786</td>\n",
       "      <td>-2.016504</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 00:03:00</th>\n",
       "      <td>4.422929</td>\n",
       "      <td>-0.818937</td>\n",
       "      <td>2.167223</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>2.136176</td>\n",
       "      <td>3.486304</td>\n",
       "      <td>6.072422</td>\n",
       "      <td>6.357409</td>\n",
       "      <td>11.013483</td>\n",
       "      <td>-2.015528</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 00:04:00</th>\n",
       "      <td>4.422569</td>\n",
       "      <td>-0.818937</td>\n",
       "      <td>2.166651</td>\n",
       "      <td>0.019508</td>\n",
       "      <td>2.135349</td>\n",
       "      <td>3.485937</td>\n",
       "      <td>6.071476</td>\n",
       "      <td>6.357201</td>\n",
       "      <td>11.012911</td>\n",
       "      <td>-2.015303</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AAVE_close  ADA_close  APT_close  ARB_close  ATOM_close  \\\n",
       "timestamp                                                                      \n",
       "2024-05-01 00:00:00    4.423169  -0.818257   2.166078   0.021370    2.136176   \n",
       "2024-05-01 00:01:00    4.422809  -0.819164   2.164012   0.020195    2.138418   \n",
       "2024-05-01 00:02:00    4.421368  -0.819845   2.163553   0.018527    2.136294   \n",
       "2024-05-01 00:03:00    4.422929  -0.818937   2.167223   0.020097    2.136176   \n",
       "2024-05-01 00:04:00    4.422569  -0.818937   2.166651   0.019508    2.135349   \n",
       "\n",
       "                     AVAX_close  BCH_close  BNB_close  BTC_close  DOGE_close  \\\n",
       "timestamp                                                                      \n",
       "2024-05-01 00:00:00    3.486794   6.072814   6.358864  11.013869   -2.014703   \n",
       "2024-05-01 00:01:00    3.485937   6.071938   6.357825  11.014249   -2.014703   \n",
       "2024-05-01 00:02:00    3.485630   6.070992   6.357634  11.012786   -2.016504   \n",
       "2024-05-01 00:03:00    3.486304   6.072422   6.357409  11.013483   -2.015528   \n",
       "2024-05-01 00:04:00    3.485937   6.071476   6.357201  11.012911   -2.015303   \n",
       "\n",
       "                     ...  TRX_XRP_spread  TRX_XRP_beta  TRX_XRP_alpha  \\\n",
       "timestamp            ...                                                \n",
       "2024-05-01 00:00:00  ...             NaN           NaN            NaN   \n",
       "2024-05-01 00:01:00  ...             NaN           NaN            NaN   \n",
       "2024-05-01 00:02:00  ...             NaN           NaN            NaN   \n",
       "2024-05-01 00:03:00  ...             NaN           NaN            NaN   \n",
       "2024-05-01 00:04:00  ...             NaN           NaN            NaN   \n",
       "\n",
       "                     TRX_XRP_adf_p  TRX_XRP_corr  BTC_TRX_spread  \\\n",
       "timestamp                                                          \n",
       "2024-05-01 00:00:00            NaN           NaN             NaN   \n",
       "2024-05-01 00:01:00            NaN           NaN             NaN   \n",
       "2024-05-01 00:02:00            NaN           NaN             NaN   \n",
       "2024-05-01 00:03:00            NaN           NaN             NaN   \n",
       "2024-05-01 00:04:00            NaN           NaN             NaN   \n",
       "\n",
       "                     BTC_TRX_beta  BTC_TRX_alpha  BTC_TRX_adf_p  BTC_TRX_corr  \n",
       "timestamp                                                                      \n",
       "2024-05-01 00:00:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-01 00:01:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-01 00:02:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-01 00:03:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-01 00:04:00           NaN            NaN            NaN           NaN  \n",
       "\n",
       "[5 rows x 330 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = build_full_features(crypto_data, top_pairs_per_window)\n",
    "print(full_df.shape)\n",
    "full_df.head()\n",
    "# 25 assets + 61 (pairs) spread features*5 = 330 columns total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846fc3bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'numpy.ndarray' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# for each window and pair, assign beta, alpha, and calculate spread for that window\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (start, end), pairs \u001b[38;5;129;01min\u001b[39;00m top_pairs_per_window.items():\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     mask = (\u001b[43mfull_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m) & (full_df[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m] <= end)\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pair_info \u001b[38;5;129;01min\u001b[39;00m pairs:\n\u001b[32m     24\u001b[39m         sym1, sym2 = pair_info[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py:60\u001b[39m, in \u001b[36mOpsMixin.__ge__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__ge__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:6130\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6127\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6128\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6130\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\isaen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:330\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mLengths must match to compare\u001b[39m\u001b[33m\"\u001b[39m, lvalues.shape, rvalues.shape\n\u001b[32m    323\u001b[39m         )\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    326\u001b[39m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[32m    327\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m lvalues.dtype != \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    328\u001b[39m ):\n\u001b[32m    329\u001b[39m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     res_values = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator.ne:\n",
      "\u001b[31mTypeError\u001b[39m: '>=' not supported between instances of 'numpy.ndarray' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "# # creation a DataFrame with all 1-min timestamps and prices for all symbols in cointegrated pairs, and window-specific spreads\n",
    "\n",
    "# #Get all unique symbols from cointegrated pairs\n",
    "# all_symbols = set()\n",
    "# for pairs in top_pairs_per_window.values():\n",
    "#     for pair_info in pairs:\n",
    "#         sym1, sym2 = pair_info[0]\n",
    "#         all_symbols.add(sym1)\n",
    "#         all_symbols.add(sym2)\n",
    "# all_symbols = sorted(list(all_symbols))\n",
    "\n",
    "# full_df = pd.DataFrame({\"timestamp\": crypto_data[\"BTC\"][\"timestamp\"]})  # index of any crypto is in fact timestamps - take any\n",
    "\n",
    "# # price columns for each symbol\n",
    "# for sym in all_symbols:\n",
    "#     df = crypto_data[sym].copy()\n",
    "#     full_df = full_df.merge(df[[\"timestamp\", \"close\"]], on=\"timestamp\", how=\"left\")\n",
    "#     full_df = full_df.rename(columns={\"close\": f\"{sym}_close\"})\n",
    "\n",
    "# # for each window and pair, assign beta, alpha, and calculate spread for that window\n",
    "# for (start, end), pairs in top_pairs_per_window.items():\n",
    "#     mask = (full_df[\"timestamp\"] >= start) & (full_df[\"timestamp\"] <= end)\n",
    "#     for pair_info in pairs:\n",
    "#         sym1, sym2 = pair_info[0]\n",
    "#         corr, beta, alpha, adf_p = pair_info[1:]\n",
    "#         spread_col = f\"{sym1}_{sym2}_spread\"\n",
    "#         if spread_col not in full_df.columns:\n",
    "#             full_df[spread_col] = np.nan\n",
    "#         y = full_df.loc[mask, f\"{sym1}_close\"]\n",
    "#         x = full_df.loc[mask, f\"{sym2}_close\"]\n",
    "#         full_df.loc[mask, spread_col] = y - (alpha + beta * x)\n",
    "#         full_df.loc[mask, f\"{sym1}_{sym2}_beta\"] = beta\n",
    "#         full_df.loc[mask, f\"{sym1}_{sym2}_alpha\"] = alpha\n",
    "#         full_df.loc[mask, f\"{sym1}_{sym2}_adf_p\"] = adf_p\n",
    "#         full_df.loc[mask, f\"{sym1}_{sym2}_corr\"] = corr\n",
    "\n",
    "# full_df.head()\n",
    "# # 55 (pairs) spread features*5 + 23 (assets) price features + 1 timestamp = 299 columns total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34029cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAVE_close        4.423169\n",
       "ADA_close        -0.818257\n",
       "APT_close         2.166078\n",
       "ARB_close         0.021370\n",
       "ATOM_close        2.136176\n",
       "                    ...   \n",
       "BTC_TRX_spread         NaN\n",
       "BTC_TRX_beta           NaN\n",
       "BTC_TRX_alpha          NaN\n",
       "BTC_TRX_adf_p          NaN\n",
       "BTC_TRX_corr           NaN\n",
       "Name: 2024-05-01 00:00:00, Length: 330, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d76abdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAVE_close</th>\n",
       "      <th>ADA_close</th>\n",
       "      <th>APT_close</th>\n",
       "      <th>ARB_close</th>\n",
       "      <th>ATOM_close</th>\n",
       "      <th>AVAX_close</th>\n",
       "      <th>BCH_close</th>\n",
       "      <th>BNB_close</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>DOGE_close</th>\n",
       "      <th>...</th>\n",
       "      <th>TRX_XRP_spread</th>\n",
       "      <th>TRX_XRP_beta</th>\n",
       "      <th>TRX_XRP_alpha</th>\n",
       "      <th>TRX_XRP_adf_p</th>\n",
       "      <th>TRX_XRP_corr</th>\n",
       "      <th>BTC_TRX_spread</th>\n",
       "      <th>BTC_TRX_beta</th>\n",
       "      <th>BTC_TRX_alpha</th>\n",
       "      <th>BTC_TRX_adf_p</th>\n",
       "      <th>BTC_TRX_corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:00:00</th>\n",
       "      <td>4.426044</td>\n",
       "      <td>-0.800510</td>\n",
       "      <td>2.187062</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>2.166651</td>\n",
       "      <td>3.512053</td>\n",
       "      <td>6.049828</td>\n",
       "      <td>6.329382</td>\n",
       "      <td>10.973357</td>\n",
       "      <td>-2.040221</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:01:00</th>\n",
       "      <td>4.425326</td>\n",
       "      <td>-0.800732</td>\n",
       "      <td>2.187174</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>2.164816</td>\n",
       "      <td>3.511963</td>\n",
       "      <td>6.049969</td>\n",
       "      <td>6.328740</td>\n",
       "      <td>10.974096</td>\n",
       "      <td>-2.042146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:02:00</th>\n",
       "      <td>4.425565</td>\n",
       "      <td>-0.799175</td>\n",
       "      <td>2.187174</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>2.165390</td>\n",
       "      <td>3.513007</td>\n",
       "      <td>6.051783</td>\n",
       "      <td>6.329436</td>\n",
       "      <td>10.975292</td>\n",
       "      <td>-2.039836</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:03:00</th>\n",
       "      <td>4.426880</td>\n",
       "      <td>-0.798063</td>\n",
       "      <td>2.187286</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>2.166994</td>\n",
       "      <td>3.512291</td>\n",
       "      <td>6.051972</td>\n",
       "      <td>6.330505</td>\n",
       "      <td>10.975792</td>\n",
       "      <td>-2.038069</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:04:00</th>\n",
       "      <td>4.430221</td>\n",
       "      <td>-0.796510</td>\n",
       "      <td>2.189976</td>\n",
       "      <td>0.033822</td>\n",
       "      <td>2.168711</td>\n",
       "      <td>3.514169</td>\n",
       "      <td>6.056362</td>\n",
       "      <td>6.332107</td>\n",
       "      <td>10.977635</td>\n",
       "      <td>-2.035846</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AAVE_close  ADA_close  APT_close  ARB_close  ATOM_close  \\\n",
       "timestamp                                                                      \n",
       "2024-05-02 00:00:00    4.426044  -0.800510   2.187062   0.027907    2.166651   \n",
       "2024-05-02 00:01:00    4.425326  -0.800732   2.187174   0.027031    2.164816   \n",
       "2024-05-02 00:02:00    4.425565  -0.799175   2.187174   0.028587    2.165390   \n",
       "2024-05-02 00:03:00    4.426880  -0.798063   2.187286   0.030820    2.166994   \n",
       "2024-05-02 00:04:00    4.430221  -0.796510   2.189976   0.033822    2.168711   \n",
       "\n",
       "                     AVAX_close  BCH_close  BNB_close  BTC_close  DOGE_close  \\\n",
       "timestamp                                                                      \n",
       "2024-05-02 00:00:00    3.512053   6.049828   6.329382  10.973357   -2.040221   \n",
       "2024-05-02 00:01:00    3.511963   6.049969   6.328740  10.974096   -2.042146   \n",
       "2024-05-02 00:02:00    3.513007   6.051783   6.329436  10.975292   -2.039836   \n",
       "2024-05-02 00:03:00    3.512291   6.051972   6.330505  10.975792   -2.038069   \n",
       "2024-05-02 00:04:00    3.514169   6.056362   6.332107  10.977635   -2.035846   \n",
       "\n",
       "                     ...  TRX_XRP_spread  TRX_XRP_beta  TRX_XRP_alpha  \\\n",
       "timestamp            ...                                                \n",
       "2024-05-02 00:00:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:01:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:02:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:03:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:04:00  ...             NaN           NaN            NaN   \n",
       "\n",
       "                     TRX_XRP_adf_p  TRX_XRP_corr  BTC_TRX_spread  \\\n",
       "timestamp                                                          \n",
       "2024-05-02 00:00:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:01:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:02:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:03:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:04:00            NaN           NaN             NaN   \n",
       "\n",
       "                     BTC_TRX_beta  BTC_TRX_alpha  BTC_TRX_adf_p  BTC_TRX_corr  \n",
       "timestamp                                                                      \n",
       "2024-05-02 00:00:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:01:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:02:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:03:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:04:00           NaN            NaN            NaN           NaN  \n",
       "\n",
       "[5 rows x 330 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_counts = full_df.notna().sum(axis=1)\n",
    "\n",
    "# Filter rows where n_NaN is NOT in the allowed set\n",
    "allowed = [25, 30, 35, 40, 45, 50]\n",
    "problematic_rows = full_df[~na_counts.isin(allowed)]\n",
    "\n",
    "problematic_rows.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2843eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAVE_close</th>\n",
       "      <th>ADA_close</th>\n",
       "      <th>APT_close</th>\n",
       "      <th>ARB_close</th>\n",
       "      <th>ATOM_close</th>\n",
       "      <th>AVAX_close</th>\n",
       "      <th>BCH_close</th>\n",
       "      <th>BNB_close</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>DOGE_close</th>\n",
       "      <th>...</th>\n",
       "      <th>TRX_XRP_spread</th>\n",
       "      <th>TRX_XRP_beta</th>\n",
       "      <th>TRX_XRP_alpha</th>\n",
       "      <th>TRX_XRP_adf_p</th>\n",
       "      <th>TRX_XRP_corr</th>\n",
       "      <th>BTC_TRX_spread</th>\n",
       "      <th>BTC_TRX_beta</th>\n",
       "      <th>BTC_TRX_alpha</th>\n",
       "      <th>BTC_TRX_adf_p</th>\n",
       "      <th>BTC_TRX_corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:00:00</th>\n",
       "      <td>4.426044</td>\n",
       "      <td>-0.800510</td>\n",
       "      <td>2.187062</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>2.166651</td>\n",
       "      <td>3.512053</td>\n",
       "      <td>6.049828</td>\n",
       "      <td>6.329382</td>\n",
       "      <td>10.973357</td>\n",
       "      <td>-2.040221</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:01:00</th>\n",
       "      <td>4.425326</td>\n",
       "      <td>-0.800732</td>\n",
       "      <td>2.187174</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>2.164816</td>\n",
       "      <td>3.511963</td>\n",
       "      <td>6.049969</td>\n",
       "      <td>6.328740</td>\n",
       "      <td>10.974096</td>\n",
       "      <td>-2.042146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:02:00</th>\n",
       "      <td>4.425565</td>\n",
       "      <td>-0.799175</td>\n",
       "      <td>2.187174</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>2.165390</td>\n",
       "      <td>3.513007</td>\n",
       "      <td>6.051783</td>\n",
       "      <td>6.329436</td>\n",
       "      <td>10.975292</td>\n",
       "      <td>-2.039836</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:03:00</th>\n",
       "      <td>4.426880</td>\n",
       "      <td>-0.798063</td>\n",
       "      <td>2.187286</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>2.166994</td>\n",
       "      <td>3.512291</td>\n",
       "      <td>6.051972</td>\n",
       "      <td>6.330505</td>\n",
       "      <td>10.975792</td>\n",
       "      <td>-2.038069</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:04:00</th>\n",
       "      <td>4.430221</td>\n",
       "      <td>-0.796510</td>\n",
       "      <td>2.189976</td>\n",
       "      <td>0.033822</td>\n",
       "      <td>2.168711</td>\n",
       "      <td>3.514169</td>\n",
       "      <td>6.056362</td>\n",
       "      <td>6.332107</td>\n",
       "      <td>10.977635</td>\n",
       "      <td>-2.035846</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29 23:55:00</th>\n",
       "      <td>5.109998</td>\n",
       "      <td>-0.362549</td>\n",
       "      <td>1.692179</td>\n",
       "      <td>-1.115657</td>\n",
       "      <td>1.475678</td>\n",
       "      <td>3.069169</td>\n",
       "      <td>5.894816</td>\n",
       "      <td>6.398179</td>\n",
       "      <td>11.453195</td>\n",
       "      <td>-1.745716</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29 23:56:00</th>\n",
       "      <td>5.109636</td>\n",
       "      <td>-0.363268</td>\n",
       "      <td>1.692234</td>\n",
       "      <td>-1.115962</td>\n",
       "      <td>1.475907</td>\n",
       "      <td>3.069308</td>\n",
       "      <td>5.894981</td>\n",
       "      <td>6.397813</td>\n",
       "      <td>11.452964</td>\n",
       "      <td>-1.746174</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29 23:57:00</th>\n",
       "      <td>5.110179</td>\n",
       "      <td>-0.363412</td>\n",
       "      <td>1.692565</td>\n",
       "      <td>-1.115352</td>\n",
       "      <td>1.476592</td>\n",
       "      <td>3.070376</td>\n",
       "      <td>5.895944</td>\n",
       "      <td>6.397829</td>\n",
       "      <td>11.453304</td>\n",
       "      <td>-1.745945</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29 23:58:00</th>\n",
       "      <td>5.109817</td>\n",
       "      <td>-0.362980</td>\n",
       "      <td>1.691331</td>\n",
       "      <td>-1.115352</td>\n",
       "      <td>1.476135</td>\n",
       "      <td>3.070469</td>\n",
       "      <td>5.895834</td>\n",
       "      <td>6.397763</td>\n",
       "      <td>11.453290</td>\n",
       "      <td>-1.745601</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29 23:59:00</th>\n",
       "      <td>5.108850</td>\n",
       "      <td>-0.363700</td>\n",
       "      <td>1.691018</td>\n",
       "      <td>-1.115657</td>\n",
       "      <td>1.475449</td>\n",
       "      <td>3.070237</td>\n",
       "      <td>5.895999</td>\n",
       "      <td>6.398046</td>\n",
       "      <td>11.453177</td>\n",
       "      <td>-1.745659</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522720 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AAVE_close  ADA_close  APT_close  ARB_close  ATOM_close  \\\n",
       "timestamp                                                                      \n",
       "2024-05-02 00:00:00    4.426044  -0.800510   2.187062   0.027907    2.166651   \n",
       "2024-05-02 00:01:00    4.425326  -0.800732   2.187174   0.027031    2.164816   \n",
       "2024-05-02 00:02:00    4.425565  -0.799175   2.187174   0.028587    2.165390   \n",
       "2024-05-02 00:03:00    4.426880  -0.798063   2.187286   0.030820    2.166994   \n",
       "2024-05-02 00:04:00    4.430221  -0.796510   2.189976   0.033822    2.168711   \n",
       "...                         ...        ...        ...        ...         ...   \n",
       "2025-04-29 23:55:00    5.109998  -0.362549   1.692179  -1.115657    1.475678   \n",
       "2025-04-29 23:56:00    5.109636  -0.363268   1.692234  -1.115962    1.475907   \n",
       "2025-04-29 23:57:00    5.110179  -0.363412   1.692565  -1.115352    1.476592   \n",
       "2025-04-29 23:58:00    5.109817  -0.362980   1.691331  -1.115352    1.476135   \n",
       "2025-04-29 23:59:00    5.108850  -0.363700   1.691018  -1.115657    1.475449   \n",
       "\n",
       "                     AVAX_close  BCH_close  BNB_close  BTC_close  DOGE_close  \\\n",
       "timestamp                                                                      \n",
       "2024-05-02 00:00:00    3.512053   6.049828   6.329382  10.973357   -2.040221   \n",
       "2024-05-02 00:01:00    3.511963   6.049969   6.328740  10.974096   -2.042146   \n",
       "2024-05-02 00:02:00    3.513007   6.051783   6.329436  10.975292   -2.039836   \n",
       "2024-05-02 00:03:00    3.512291   6.051972   6.330505  10.975792   -2.038069   \n",
       "2024-05-02 00:04:00    3.514169   6.056362   6.332107  10.977635   -2.035846   \n",
       "...                         ...        ...        ...        ...         ...   \n",
       "2025-04-29 23:55:00    3.069169   5.894816   6.398179  11.453195   -1.745716   \n",
       "2025-04-29 23:56:00    3.069308   5.894981   6.397813  11.452964   -1.746174   \n",
       "2025-04-29 23:57:00    3.070376   5.895944   6.397829  11.453304   -1.745945   \n",
       "2025-04-29 23:58:00    3.070469   5.895834   6.397763  11.453290   -1.745601   \n",
       "2025-04-29 23:59:00    3.070237   5.895999   6.398046  11.453177   -1.745659   \n",
       "\n",
       "                     ...  TRX_XRP_spread  TRX_XRP_beta  TRX_XRP_alpha  \\\n",
       "timestamp            ...                                                \n",
       "2024-05-02 00:00:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:01:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:02:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:03:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:04:00  ...             NaN           NaN            NaN   \n",
       "...                  ...             ...           ...            ...   \n",
       "2025-04-29 23:55:00  ...             NaN           NaN            NaN   \n",
       "2025-04-29 23:56:00  ...             NaN           NaN            NaN   \n",
       "2025-04-29 23:57:00  ...             NaN           NaN            NaN   \n",
       "2025-04-29 23:58:00  ...             NaN           NaN            NaN   \n",
       "2025-04-29 23:59:00  ...             NaN           NaN            NaN   \n",
       "\n",
       "                     TRX_XRP_adf_p  TRX_XRP_corr  BTC_TRX_spread  \\\n",
       "timestamp                                                          \n",
       "2024-05-02 00:00:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:01:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:02:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:03:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:04:00            NaN           NaN             NaN   \n",
       "...                            ...           ...             ...   \n",
       "2025-04-29 23:55:00            NaN           NaN             NaN   \n",
       "2025-04-29 23:56:00            NaN           NaN             NaN   \n",
       "2025-04-29 23:57:00            NaN           NaN             NaN   \n",
       "2025-04-29 23:58:00            NaN           NaN             NaN   \n",
       "2025-04-29 23:59:00            NaN           NaN             NaN   \n",
       "\n",
       "                     BTC_TRX_beta  BTC_TRX_alpha  BTC_TRX_adf_p  BTC_TRX_corr  \n",
       "timestamp                                                                      \n",
       "2024-05-02 00:00:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:01:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:02:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:03:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:04:00           NaN            NaN            NaN           NaN  \n",
       "...                           ...            ...            ...           ...  \n",
       "2025-04-29 23:55:00           NaN            NaN            NaN           NaN  \n",
       "2025-04-29 23:56:00           NaN            NaN            NaN           NaN  \n",
       "2025-04-29 23:57:00           NaN            NaN            NaN           NaN  \n",
       "2025-04-29 23:58:00           NaN            NaN            NaN           NaN  \n",
       "2025-04-29 23:59:00           NaN            NaN            NaN           NaN  \n",
       "\n",
       "[522720 rows x 330 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problematic_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7089ab1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAVE_close</th>\n",
       "      <th>ADA_close</th>\n",
       "      <th>APT_close</th>\n",
       "      <th>ARB_close</th>\n",
       "      <th>ATOM_close</th>\n",
       "      <th>AVAX_close</th>\n",
       "      <th>BCH_close</th>\n",
       "      <th>BNB_close</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>DOGE_close</th>\n",
       "      <th>...</th>\n",
       "      <th>TRX_XRP_spread</th>\n",
       "      <th>TRX_XRP_beta</th>\n",
       "      <th>TRX_XRP_alpha</th>\n",
       "      <th>TRX_XRP_adf_p</th>\n",
       "      <th>TRX_XRP_corr</th>\n",
       "      <th>BTC_TRX_spread</th>\n",
       "      <th>BTC_TRX_beta</th>\n",
       "      <th>BTC_TRX_alpha</th>\n",
       "      <th>BTC_TRX_adf_p</th>\n",
       "      <th>BTC_TRX_corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:00:00</th>\n",
       "      <td>4.426044</td>\n",
       "      <td>-0.800510</td>\n",
       "      <td>2.187062</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>2.166651</td>\n",
       "      <td>3.512053</td>\n",
       "      <td>6.049828</td>\n",
       "      <td>6.329382</td>\n",
       "      <td>10.973357</td>\n",
       "      <td>-2.040221</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:01:00</th>\n",
       "      <td>4.425326</td>\n",
       "      <td>-0.800732</td>\n",
       "      <td>2.187174</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>2.164816</td>\n",
       "      <td>3.511963</td>\n",
       "      <td>6.049969</td>\n",
       "      <td>6.328740</td>\n",
       "      <td>10.974096</td>\n",
       "      <td>-2.042146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:02:00</th>\n",
       "      <td>4.425565</td>\n",
       "      <td>-0.799175</td>\n",
       "      <td>2.187174</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>2.165390</td>\n",
       "      <td>3.513007</td>\n",
       "      <td>6.051783</td>\n",
       "      <td>6.329436</td>\n",
       "      <td>10.975292</td>\n",
       "      <td>-2.039836</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:03:00</th>\n",
       "      <td>4.426880</td>\n",
       "      <td>-0.798063</td>\n",
       "      <td>2.187286</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>2.166994</td>\n",
       "      <td>3.512291</td>\n",
       "      <td>6.051972</td>\n",
       "      <td>6.330505</td>\n",
       "      <td>10.975792</td>\n",
       "      <td>-2.038069</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:04:00</th>\n",
       "      <td>4.430221</td>\n",
       "      <td>-0.796510</td>\n",
       "      <td>2.189976</td>\n",
       "      <td>0.033822</td>\n",
       "      <td>2.168711</td>\n",
       "      <td>3.514169</td>\n",
       "      <td>6.056362</td>\n",
       "      <td>6.332107</td>\n",
       "      <td>10.977635</td>\n",
       "      <td>-2.035846</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29 23:56:00</th>\n",
       "      <td>5.109636</td>\n",
       "      <td>-0.363268</td>\n",
       "      <td>1.692234</td>\n",
       "      <td>-1.115962</td>\n",
       "      <td>1.475907</td>\n",
       "      <td>3.069308</td>\n",
       "      <td>5.894981</td>\n",
       "      <td>6.397813</td>\n",
       "      <td>11.452964</td>\n",
       "      <td>-1.746174</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29 23:57:00</th>\n",
       "      <td>5.110179</td>\n",
       "      <td>-0.363412</td>\n",
       "      <td>1.692565</td>\n",
       "      <td>-1.115352</td>\n",
       "      <td>1.476592</td>\n",
       "      <td>3.070376</td>\n",
       "      <td>5.895944</td>\n",
       "      <td>6.397829</td>\n",
       "      <td>11.453304</td>\n",
       "      <td>-1.745945</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29 23:58:00</th>\n",
       "      <td>5.109817</td>\n",
       "      <td>-0.362980</td>\n",
       "      <td>1.691331</td>\n",
       "      <td>-1.115352</td>\n",
       "      <td>1.476135</td>\n",
       "      <td>3.070469</td>\n",
       "      <td>5.895834</td>\n",
       "      <td>6.397763</td>\n",
       "      <td>11.453290</td>\n",
       "      <td>-1.745601</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-29 23:59:00</th>\n",
       "      <td>5.108850</td>\n",
       "      <td>-0.363700</td>\n",
       "      <td>1.691018</td>\n",
       "      <td>-1.115657</td>\n",
       "      <td>1.475449</td>\n",
       "      <td>3.070237</td>\n",
       "      <td>5.895999</td>\n",
       "      <td>6.398046</td>\n",
       "      <td>11.453177</td>\n",
       "      <td>-1.745659</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-01 00:00:00</th>\n",
       "      <td>5.101390</td>\n",
       "      <td>-0.383899</td>\n",
       "      <td>1.676236</td>\n",
       "      <td>-1.121779</td>\n",
       "      <td>1.456287</td>\n",
       "      <td>3.039318</td>\n",
       "      <td>5.903070</td>\n",
       "      <td>6.395228</td>\n",
       "      <td>11.452176</td>\n",
       "      <td>-1.759389</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522721 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AAVE_close  ADA_close  APT_close  ARB_close  ATOM_close  \\\n",
       "timestamp                                                                      \n",
       "2024-05-02 00:00:00    4.426044  -0.800510   2.187062   0.027907    2.166651   \n",
       "2024-05-02 00:01:00    4.425326  -0.800732   2.187174   0.027031    2.164816   \n",
       "2024-05-02 00:02:00    4.425565  -0.799175   2.187174   0.028587    2.165390   \n",
       "2024-05-02 00:03:00    4.426880  -0.798063   2.187286   0.030820    2.166994   \n",
       "2024-05-02 00:04:00    4.430221  -0.796510   2.189976   0.033822    2.168711   \n",
       "...                         ...        ...        ...        ...         ...   \n",
       "2025-04-29 23:56:00    5.109636  -0.363268   1.692234  -1.115962    1.475907   \n",
       "2025-04-29 23:57:00    5.110179  -0.363412   1.692565  -1.115352    1.476592   \n",
       "2025-04-29 23:58:00    5.109817  -0.362980   1.691331  -1.115352    1.476135   \n",
       "2025-04-29 23:59:00    5.108850  -0.363700   1.691018  -1.115657    1.475449   \n",
       "2025-05-01 00:00:00    5.101390  -0.383899   1.676236  -1.121779    1.456287   \n",
       "\n",
       "                     AVAX_close  BCH_close  BNB_close  BTC_close  DOGE_close  \\\n",
       "timestamp                                                                      \n",
       "2024-05-02 00:00:00    3.512053   6.049828   6.329382  10.973357   -2.040221   \n",
       "2024-05-02 00:01:00    3.511963   6.049969   6.328740  10.974096   -2.042146   \n",
       "2024-05-02 00:02:00    3.513007   6.051783   6.329436  10.975292   -2.039836   \n",
       "2024-05-02 00:03:00    3.512291   6.051972   6.330505  10.975792   -2.038069   \n",
       "2024-05-02 00:04:00    3.514169   6.056362   6.332107  10.977635   -2.035846   \n",
       "...                         ...        ...        ...        ...         ...   \n",
       "2025-04-29 23:56:00    3.069308   5.894981   6.397813  11.452964   -1.746174   \n",
       "2025-04-29 23:57:00    3.070376   5.895944   6.397829  11.453304   -1.745945   \n",
       "2025-04-29 23:58:00    3.070469   5.895834   6.397763  11.453290   -1.745601   \n",
       "2025-04-29 23:59:00    3.070237   5.895999   6.398046  11.453177   -1.745659   \n",
       "2025-05-01 00:00:00    3.039318   5.903070   6.395228  11.452176   -1.759389   \n",
       "\n",
       "                     ...  TRX_XRP_spread  TRX_XRP_beta  TRX_XRP_alpha  \\\n",
       "timestamp            ...                                                \n",
       "2024-05-02 00:00:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:01:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:02:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:03:00  ...             NaN           NaN            NaN   \n",
       "2024-05-02 00:04:00  ...             NaN           NaN            NaN   \n",
       "...                  ...             ...           ...            ...   \n",
       "2025-04-29 23:56:00  ...             NaN           NaN            NaN   \n",
       "2025-04-29 23:57:00  ...             NaN           NaN            NaN   \n",
       "2025-04-29 23:58:00  ...             NaN           NaN            NaN   \n",
       "2025-04-29 23:59:00  ...             NaN           NaN            NaN   \n",
       "2025-05-01 00:00:00  ...             NaN           NaN            NaN   \n",
       "\n",
       "                     TRX_XRP_adf_p  TRX_XRP_corr  BTC_TRX_spread  \\\n",
       "timestamp                                                          \n",
       "2024-05-02 00:00:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:01:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:02:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:03:00            NaN           NaN             NaN   \n",
       "2024-05-02 00:04:00            NaN           NaN             NaN   \n",
       "...                            ...           ...             ...   \n",
       "2025-04-29 23:56:00            NaN           NaN             NaN   \n",
       "2025-04-29 23:57:00            NaN           NaN             NaN   \n",
       "2025-04-29 23:58:00            NaN           NaN             NaN   \n",
       "2025-04-29 23:59:00            NaN           NaN             NaN   \n",
       "2025-05-01 00:00:00            NaN           NaN             NaN   \n",
       "\n",
       "                     BTC_TRX_beta  BTC_TRX_alpha  BTC_TRX_adf_p  BTC_TRX_corr  \n",
       "timestamp                                                                      \n",
       "2024-05-02 00:00:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:01:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:02:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:03:00           NaN            NaN            NaN           NaN  \n",
       "2024-05-02 00:04:00           NaN            NaN            NaN           NaN  \n",
       "...                           ...            ...            ...           ...  \n",
       "2025-04-29 23:56:00           NaN            NaN            NaN           NaN  \n",
       "2025-04-29 23:57:00           NaN            NaN            NaN           NaN  \n",
       "2025-04-29 23:58:00           NaN            NaN            NaN           NaN  \n",
       "2025-04-29 23:59:00           NaN            NaN            NaN           NaN  \n",
       "2025-05-01 00:00:00           NaN            NaN            NaN           NaN  \n",
       "\n",
       "[522721 rows x 330 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[~(full_df.isna().sum(axis=1) == (330-25-5*5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2cc1259",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"bin_futures_historical_pairs_with_spreads.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9612e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [full_df.iloc[i].isna().sum() for i in range(len(full_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85200ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{230, 235, 240, 245, 250, 255, 260, 265, 270, 280, 305}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values in l\n",
    "set(l)\n",
    "# 230 = 330 - 50*2 (overlap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c7e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAVE_close', 'ADA_close', 'APT_close', 'ARB_close', 'ATOM_close',\n",
       "       'AVAX_close', 'BCH_close', 'BNB_close', 'BTC_close', 'DOGE_close',\n",
       "       ...\n",
       "       'TRX_XRP_spread', 'TRX_XRP_beta', 'TRX_XRP_alpha', 'TRX_XRP_adf_p',\n",
       "       'TRX_XRP_corr', 'BTC_TRX_spread', 'BTC_TRX_beta', 'BTC_TRX_alpha',\n",
       "       'BTC_TRX_adf_p', 'BTC_TRX_corr'],\n",
       "      dtype='object', length=330)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c202a0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAVE_close</th>\n",
       "      <th>ADA_close</th>\n",
       "      <th>APT_close</th>\n",
       "      <th>ARB_close</th>\n",
       "      <th>ATOM_close</th>\n",
       "      <th>AVAX_close</th>\n",
       "      <th>BCH_close</th>\n",
       "      <th>BNB_close</th>\n",
       "      <th>BTC_close</th>\n",
       "      <th>DOGE_close</th>\n",
       "      <th>...</th>\n",
       "      <th>TRX_XRP_spread</th>\n",
       "      <th>TRX_XRP_beta</th>\n",
       "      <th>TRX_XRP_alpha</th>\n",
       "      <th>TRX_XRP_adf_p</th>\n",
       "      <th>TRX_XRP_corr</th>\n",
       "      <th>BTC_TRX_spread</th>\n",
       "      <th>BTC_TRX_beta</th>\n",
       "      <th>BTC_TRX_alpha</th>\n",
       "      <th>BTC_TRX_adf_p</th>\n",
       "      <th>BTC_TRX_corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-06 00:00:00</th>\n",
       "      <td>4.378520</td>\n",
       "      <td>-1.052970</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>-0.475137</td>\n",
       "      <td>1.739062</td>\n",
       "      <td>3.221113</td>\n",
       "      <td>5.783025</td>\n",
       "      <td>6.209334</td>\n",
       "      <td>10.943623</td>\n",
       "      <td>-2.253985</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-06 00:01:00</th>\n",
       "      <td>4.375631</td>\n",
       "      <td>-1.054117</td>\n",
       "      <td>1.709464</td>\n",
       "      <td>-0.476102</td>\n",
       "      <td>1.737303</td>\n",
       "      <td>3.220634</td>\n",
       "      <td>5.781638</td>\n",
       "      <td>6.208691</td>\n",
       "      <td>10.943123</td>\n",
       "      <td>-2.253509</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-06 00:02:00</th>\n",
       "      <td>4.377516</td>\n",
       "      <td>-1.053257</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>-0.474172</td>\n",
       "      <td>1.738534</td>\n",
       "      <td>3.221831</td>\n",
       "      <td>5.783056</td>\n",
       "      <td>6.209495</td>\n",
       "      <td>10.943651</td>\n",
       "      <td>-2.250942</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-06 00:03:00</th>\n",
       "      <td>4.375002</td>\n",
       "      <td>-1.054978</td>\n",
       "      <td>1.708015</td>\n",
       "      <td>-0.477713</td>\n",
       "      <td>1.736071</td>\n",
       "      <td>3.219076</td>\n",
       "      <td>5.780280</td>\n",
       "      <td>6.207442</td>\n",
       "      <td>10.942666</td>\n",
       "      <td>-2.255225</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-06 00:04:00</th>\n",
       "      <td>4.375757</td>\n",
       "      <td>-1.054404</td>\n",
       "      <td>1.709102</td>\n",
       "      <td>-0.476907</td>\n",
       "      <td>1.738007</td>\n",
       "      <td>3.219755</td>\n",
       "      <td>5.781052</td>\n",
       "      <td>6.207060</td>\n",
       "      <td>10.941891</td>\n",
       "      <td>-2.255415</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-13 23:55:00</th>\n",
       "      <td>5.091109</td>\n",
       "      <td>-0.354249</td>\n",
       "      <td>1.637753</td>\n",
       "      <td>-1.069442</td>\n",
       "      <td>1.362002</td>\n",
       "      <td>2.917554</td>\n",
       "      <td>5.786621</td>\n",
       "      <td>6.361579</td>\n",
       "      <td>11.303464</td>\n",
       "      <td>-1.801810</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-13 23:56:00</th>\n",
       "      <td>5.092584</td>\n",
       "      <td>-0.353537</td>\n",
       "      <td>1.638647</td>\n",
       "      <td>-1.068568</td>\n",
       "      <td>1.362770</td>\n",
       "      <td>2.917717</td>\n",
       "      <td>5.786683</td>\n",
       "      <td>6.361769</td>\n",
       "      <td>11.303316</td>\n",
       "      <td>-1.801567</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-13 23:57:00</th>\n",
       "      <td>5.091662</td>\n",
       "      <td>-0.354249</td>\n",
       "      <td>1.637870</td>\n",
       "      <td>-1.069151</td>\n",
       "      <td>1.361745</td>\n",
       "      <td>2.916635</td>\n",
       "      <td>5.786744</td>\n",
       "      <td>6.361855</td>\n",
       "      <td>11.303028</td>\n",
       "      <td>-1.801689</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-13 23:58:00</th>\n",
       "      <td>5.092031</td>\n",
       "      <td>-0.354392</td>\n",
       "      <td>1.638142</td>\n",
       "      <td>-1.068859</td>\n",
       "      <td>1.362002</td>\n",
       "      <td>2.917014</td>\n",
       "      <td>5.786284</td>\n",
       "      <td>6.361976</td>\n",
       "      <td>11.302799</td>\n",
       "      <td>-1.801749</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-13 23:59:00</th>\n",
       "      <td>5.092154</td>\n",
       "      <td>-0.353395</td>\n",
       "      <td>1.638531</td>\n",
       "      <td>-1.068277</td>\n",
       "      <td>1.362258</td>\n",
       "      <td>2.917554</td>\n",
       "      <td>5.785823</td>\n",
       "      <td>6.362079</td>\n",
       "      <td>11.303258</td>\n",
       "      <td>-1.801022</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4320 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AAVE_close  ADA_close  APT_close  ARB_close  ATOM_close  \\\n",
       "timestamp                                                                      \n",
       "2024-07-06 00:00:00    4.378520  -1.052970   1.710730  -0.475137    1.739062   \n",
       "2024-07-06 00:01:00    4.375631  -1.054117   1.709464  -0.476102    1.737303   \n",
       "2024-07-06 00:02:00    4.377516  -1.053257   1.710730  -0.474172    1.738534   \n",
       "2024-07-06 00:03:00    4.375002  -1.054978   1.708015  -0.477713    1.736071   \n",
       "2024-07-06 00:04:00    4.375757  -1.054404   1.709102  -0.476907    1.738007   \n",
       "...                         ...        ...        ...        ...         ...   \n",
       "2025-03-13 23:55:00    5.091109  -0.354249   1.637753  -1.069442    1.362002   \n",
       "2025-03-13 23:56:00    5.092584  -0.353537   1.638647  -1.068568    1.362770   \n",
       "2025-03-13 23:57:00    5.091662  -0.354249   1.637870  -1.069151    1.361745   \n",
       "2025-03-13 23:58:00    5.092031  -0.354392   1.638142  -1.068859    1.362002   \n",
       "2025-03-13 23:59:00    5.092154  -0.353395   1.638531  -1.068277    1.362258   \n",
       "\n",
       "                     AVAX_close  BCH_close  BNB_close  BTC_close  DOGE_close  \\\n",
       "timestamp                                                                      \n",
       "2024-07-06 00:00:00    3.221113   5.783025   6.209334  10.943623   -2.253985   \n",
       "2024-07-06 00:01:00    3.220634   5.781638   6.208691  10.943123   -2.253509   \n",
       "2024-07-06 00:02:00    3.221831   5.783056   6.209495  10.943651   -2.250942   \n",
       "2024-07-06 00:03:00    3.219076   5.780280   6.207442  10.942666   -2.255225   \n",
       "2024-07-06 00:04:00    3.219755   5.781052   6.207060  10.941891   -2.255415   \n",
       "...                         ...        ...        ...        ...         ...   \n",
       "2025-03-13 23:55:00    2.917554   5.786621   6.361579  11.303464   -1.801810   \n",
       "2025-03-13 23:56:00    2.917717   5.786683   6.361769  11.303316   -1.801567   \n",
       "2025-03-13 23:57:00    2.916635   5.786744   6.361855  11.303028   -1.801689   \n",
       "2025-03-13 23:58:00    2.917014   5.786284   6.361976  11.302799   -1.801749   \n",
       "2025-03-13 23:59:00    2.917554   5.785823   6.362079  11.303258   -1.801022   \n",
       "\n",
       "                     ...  TRX_XRP_spread  TRX_XRP_beta  TRX_XRP_alpha  \\\n",
       "timestamp            ...                                                \n",
       "2024-07-06 00:00:00  ...             NaN           NaN            NaN   \n",
       "2024-07-06 00:01:00  ...             NaN           NaN            NaN   \n",
       "2024-07-06 00:02:00  ...             NaN           NaN            NaN   \n",
       "2024-07-06 00:03:00  ...             NaN           NaN            NaN   \n",
       "2024-07-06 00:04:00  ...             NaN           NaN            NaN   \n",
       "...                  ...             ...           ...            ...   \n",
       "2025-03-13 23:55:00  ...             NaN           NaN            NaN   \n",
       "2025-03-13 23:56:00  ...             NaN           NaN            NaN   \n",
       "2025-03-13 23:57:00  ...             NaN           NaN            NaN   \n",
       "2025-03-13 23:58:00  ...             NaN           NaN            NaN   \n",
       "2025-03-13 23:59:00  ...             NaN           NaN            NaN   \n",
       "\n",
       "                     TRX_XRP_adf_p  TRX_XRP_corr  BTC_TRX_spread  \\\n",
       "timestamp                                                          \n",
       "2024-07-06 00:00:00            NaN           NaN             NaN   \n",
       "2024-07-06 00:01:00            NaN           NaN             NaN   \n",
       "2024-07-06 00:02:00            NaN           NaN             NaN   \n",
       "2024-07-06 00:03:00            NaN           NaN             NaN   \n",
       "2024-07-06 00:04:00            NaN           NaN             NaN   \n",
       "...                            ...           ...             ...   \n",
       "2025-03-13 23:55:00            NaN           NaN             NaN   \n",
       "2025-03-13 23:56:00            NaN           NaN             NaN   \n",
       "2025-03-13 23:57:00            NaN           NaN             NaN   \n",
       "2025-03-13 23:58:00            NaN           NaN             NaN   \n",
       "2025-03-13 23:59:00            NaN           NaN             NaN   \n",
       "\n",
       "                     BTC_TRX_beta  BTC_TRX_alpha  BTC_TRX_adf_p  BTC_TRX_corr  \n",
       "timestamp                                                                      \n",
       "2024-07-06 00:00:00           NaN            NaN            NaN           NaN  \n",
       "2024-07-06 00:01:00           NaN            NaN            NaN           NaN  \n",
       "2024-07-06 00:02:00           NaN            NaN            NaN           NaN  \n",
       "2024-07-06 00:03:00           NaN            NaN            NaN           NaN  \n",
       "2024-07-06 00:04:00           NaN            NaN            NaN           NaN  \n",
       "...                           ...            ...            ...           ...  \n",
       "2025-03-13 23:55:00           NaN            NaN            NaN           NaN  \n",
       "2025-03-13 23:56:00           NaN            NaN            NaN           NaN  \n",
       "2025-03-13 23:57:00           NaN            NaN            NaN           NaN  \n",
       "2025-03-13 23:58:00           NaN            NaN            NaN           NaN  \n",
       "2025-03-13 23:59:00           NaN            NaN            NaN           NaN  \n",
       "\n",
       "[4320 rows x 330 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[full_df.isna().sum(axis=1) == 230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "155707fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only 4 pairs found for window (Timestamp('2024-05-05 00:00:00'), Timestamp('2024-05-07 23:59:00'))\n",
      "Warning: Only 2 pairs found for window (Timestamp('2024-05-11 00:00:00'), Timestamp('2024-05-13 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2024-06-27 00:00:00'), Timestamp('2024-06-29 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2024-06-28 00:00:00'), Timestamp('2024-06-30 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2024-07-24 00:00:00'), Timestamp('2024-07-26 23:59:00'))\n",
      "Warning: Only 1 pairs found for window (Timestamp('2024-08-11 00:00:00'), Timestamp('2024-08-13 23:59:00'))\n",
      "Warning: Only 3 pairs found for window (Timestamp('2024-08-17 00:00:00'), Timestamp('2024-08-19 23:59:00'))\n",
      "Warning: Only 0 pairs found for window (Timestamp('2024-08-18 00:00:00'), Timestamp('2024-08-20 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2024-09-13 00:00:00'), Timestamp('2024-09-15 23:59:00'))\n",
      "Warning: Only 2 pairs found for window (Timestamp('2025-01-01 00:00:00'), Timestamp('2025-01-03 23:59:00'))\n",
      "Warning: Only 2 pairs found for window (Timestamp('2025-02-19 00:00:00'), Timestamp('2025-02-21 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2025-02-26 00:00:00'), Timestamp('2025-02-28 23:59:00'))\n",
      "Warning: Only 2 pairs found for window (Timestamp('2025-02-27 00:00:00'), Timestamp('2025-03-01 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2025-04-06 00:00:00'), Timestamp('2025-04-08 23:59:00'))\n",
      "Warning: Only 4 pairs found for window (Timestamp('2025-04-20 00:00:00'), Timestamp('2025-04-22 23:59:00'))\n"
     ]
    }
   ],
   "source": [
    "# make sure that there are 5 pairs for each window\n",
    "for window_key, pairs in top_pairs_per_window.items():\n",
    "    if len(pairs) < 5:\n",
    "        print(f\"Warning: Only {len(pairs)} pairs found for window {window_key}\")\n",
    "# not always 5 pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "659ae4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ADA', 'LTC'),\n",
       "  0.9732799084897753,\n",
       "  1.2396422632353334,\n",
       "  -6.170703490664128,\n",
       "  0.001161524286787201),\n",
       " (('LINK', 'LTC'),\n",
       "  0.9518375658442225,\n",
       "  1.196781338714112,\n",
       "  -2.4268112380017133,\n",
       "  0.017729384664906894),\n",
       " (('HBAR', 'XRP'),\n",
       "  0.9485829619792489,\n",
       "  1.151403309772805,\n",
       "  -1.7357516556295898,\n",
       "  0.018772204658598843),\n",
       " (('BTC', 'DOGE'),\n",
       "  0.9475848029186897,\n",
       "  0.5082024015560704,\n",
       "  12.078883578173878,\n",
       "  0.007458213238889828),\n",
       " (('BTC', 'XLM'),\n",
       "  0.935083325580816,\n",
       "  0.5203410772399053,\n",
       "  12.219190381233517,\n",
       "  0.006323753174875367)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pairs_per_window[(pd.Timestamp('2024-07-06 00:00:00'), pd.Timestamp('2024-07-08 23:59:00'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b50575ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(Timestamp('2024-05-01 00:00:00'), Timestamp('2024-05-03 23:59:00')), (Timestamp('2024-05-02 00:00:00'), Timestamp('2024-05-04 23:59:00')), (Timestamp('2024-05-03 00:00:00'), Timestamp('2024-05-05 23:59:00')), (Timestamp('2024-05-04 00:00:00'), Timestamp('2024-05-06 23:59:00')), (Timestamp('2024-05-05 00:00:00'), Timestamp('2024-05-07 23:59:00')), (Timestamp('2024-05-06 00:00:00'), Timestamp('2024-05-08 23:59:00')), (Timestamp('2024-05-07 00:00:00'), Timestamp('2024-05-09 23:59:00')), (Timestamp('2024-05-08 00:00:00'), Timestamp('2024-05-10 23:59:00')), (Timestamp('2024-05-09 00:00:00'), Timestamp('2024-05-11 23:59:00')), (Timestamp('2024-05-10 00:00:00'), Timestamp('2024-05-12 23:59:00')), (Timestamp('2024-05-11 00:00:00'), Timestamp('2024-05-13 23:59:00')), (Timestamp('2024-05-12 00:00:00'), Timestamp('2024-05-14 23:59:00')), (Timestamp('2024-05-13 00:00:00'), Timestamp('2024-05-15 23:59:00')), (Timestamp('2024-05-14 00:00:00'), Timestamp('2024-05-16 23:59:00')), (Timestamp('2024-05-15 00:00:00'), Timestamp('2024-05-17 23:59:00')), (Timestamp('2024-05-16 00:00:00'), Timestamp('2024-05-18 23:59:00')), (Timestamp('2024-05-17 00:00:00'), Timestamp('2024-05-19 23:59:00')), (Timestamp('2024-05-18 00:00:00'), Timestamp('2024-05-20 23:59:00')), (Timestamp('2024-05-19 00:00:00'), Timestamp('2024-05-21 23:59:00')), (Timestamp('2024-05-20 00:00:00'), Timestamp('2024-05-22 23:59:00')), (Timestamp('2024-05-21 00:00:00'), Timestamp('2024-05-23 23:59:00')), (Timestamp('2024-05-22 00:00:00'), Timestamp('2024-05-24 23:59:00')), (Timestamp('2024-05-23 00:00:00'), Timestamp('2024-05-25 23:59:00')), (Timestamp('2024-05-24 00:00:00'), Timestamp('2024-05-26 23:59:00')), (Timestamp('2024-05-25 00:00:00'), Timestamp('2024-05-27 23:59:00')), (Timestamp('2024-05-26 00:00:00'), Timestamp('2024-05-28 23:59:00')), (Timestamp('2024-05-27 00:00:00'), Timestamp('2024-05-29 23:59:00')), (Timestamp('2024-05-28 00:00:00'), Timestamp('2024-05-30 23:59:00')), (Timestamp('2024-05-29 00:00:00'), Timestamp('2024-05-31 23:59:00')), (Timestamp('2024-05-30 00:00:00'), Timestamp('2024-06-01 23:59:00')), (Timestamp('2024-05-31 00:00:00'), Timestamp('2024-06-02 23:59:00')), (Timestamp('2024-06-01 00:00:00'), Timestamp('2024-06-03 23:59:00')), (Timestamp('2024-06-02 00:00:00'), Timestamp('2024-06-04 23:59:00')), (Timestamp('2024-06-03 00:00:00'), Timestamp('2024-06-05 23:59:00')), (Timestamp('2024-06-04 00:00:00'), Timestamp('2024-06-06 23:59:00')), (Timestamp('2024-06-05 00:00:00'), Timestamp('2024-06-07 23:59:00')), (Timestamp('2024-06-06 00:00:00'), Timestamp('2024-06-08 23:59:00')), (Timestamp('2024-06-07 00:00:00'), Timestamp('2024-06-09 23:59:00')), (Timestamp('2024-06-08 00:00:00'), Timestamp('2024-06-10 23:59:00')), (Timestamp('2024-06-09 00:00:00'), Timestamp('2024-06-11 23:59:00')), (Timestamp('2024-06-10 00:00:00'), Timestamp('2024-06-12 23:59:00')), (Timestamp('2024-06-11 00:00:00'), Timestamp('2024-06-13 23:59:00')), (Timestamp('2024-06-12 00:00:00'), Timestamp('2024-06-14 23:59:00')), (Timestamp('2024-06-13 00:00:00'), Timestamp('2024-06-15 23:59:00')), (Timestamp('2024-06-14 00:00:00'), Timestamp('2024-06-16 23:59:00')), (Timestamp('2024-06-15 00:00:00'), Timestamp('2024-06-17 23:59:00')), (Timestamp('2024-06-16 00:00:00'), Timestamp('2024-06-18 23:59:00')), (Timestamp('2024-06-17 00:00:00'), Timestamp('2024-06-19 23:59:00')), (Timestamp('2024-06-18 00:00:00'), Timestamp('2024-06-20 23:59:00')), (Timestamp('2024-06-19 00:00:00'), Timestamp('2024-06-21 23:59:00')), (Timestamp('2024-06-20 00:00:00'), Timestamp('2024-06-22 23:59:00')), (Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-23 23:59:00')), (Timestamp('2024-06-22 00:00:00'), Timestamp('2024-06-24 23:59:00')), (Timestamp('2024-06-23 00:00:00'), Timestamp('2024-06-25 23:59:00')), (Timestamp('2024-06-24 00:00:00'), Timestamp('2024-06-26 23:59:00')), (Timestamp('2024-06-25 00:00:00'), Timestamp('2024-06-27 23:59:00')), (Timestamp('2024-06-26 00:00:00'), Timestamp('2024-06-28 23:59:00')), (Timestamp('2024-06-27 00:00:00'), Timestamp('2024-06-29 23:59:00')), (Timestamp('2024-06-28 00:00:00'), Timestamp('2024-06-30 23:59:00')), (Timestamp('2024-06-29 00:00:00'), Timestamp('2024-07-01 23:59:00')), (Timestamp('2024-06-30 00:00:00'), Timestamp('2024-07-02 23:59:00')), (Timestamp('2024-07-01 00:00:00'), Timestamp('2024-07-03 23:59:00')), (Timestamp('2024-07-02 00:00:00'), Timestamp('2024-07-04 23:59:00')), (Timestamp('2024-07-03 00:00:00'), Timestamp('2024-07-05 23:59:00')), (Timestamp('2024-07-04 00:00:00'), Timestamp('2024-07-06 23:59:00')), (Timestamp('2024-07-05 00:00:00'), Timestamp('2024-07-07 23:59:00')), (Timestamp('2024-07-06 00:00:00'), Timestamp('2024-07-08 23:59:00')), (Timestamp('2024-07-07 00:00:00'), Timestamp('2024-07-09 23:59:00')), (Timestamp('2024-07-08 00:00:00'), Timestamp('2024-07-10 23:59:00')), (Timestamp('2024-07-09 00:00:00'), Timestamp('2024-07-11 23:59:00')), (Timestamp('2024-07-10 00:00:00'), Timestamp('2024-07-12 23:59:00')), (Timestamp('2024-07-11 00:00:00'), Timestamp('2024-07-13 23:59:00')), (Timestamp('2024-07-12 00:00:00'), Timestamp('2024-07-14 23:59:00')), (Timestamp('2024-07-13 00:00:00'), Timestamp('2024-07-15 23:59:00')), (Timestamp('2024-07-14 00:00:00'), Timestamp('2024-07-16 23:59:00')), (Timestamp('2024-07-15 00:00:00'), Timestamp('2024-07-17 23:59:00')), (Timestamp('2024-07-16 00:00:00'), Timestamp('2024-07-18 23:59:00')), (Timestamp('2024-07-17 00:00:00'), Timestamp('2024-07-19 23:59:00')), (Timestamp('2024-07-18 00:00:00'), Timestamp('2024-07-20 23:59:00')), (Timestamp('2024-07-19 00:00:00'), Timestamp('2024-07-21 23:59:00')), (Timestamp('2024-07-20 00:00:00'), Timestamp('2024-07-22 23:59:00')), (Timestamp('2024-07-21 00:00:00'), Timestamp('2024-07-23 23:59:00')), (Timestamp('2024-07-22 00:00:00'), Timestamp('2024-07-24 23:59:00')), (Timestamp('2024-07-23 00:00:00'), Timestamp('2024-07-25 23:59:00')), (Timestamp('2024-07-24 00:00:00'), Timestamp('2024-07-26 23:59:00')), (Timestamp('2024-07-25 00:00:00'), Timestamp('2024-07-27 23:59:00')), (Timestamp('2024-07-26 00:00:00'), Timestamp('2024-07-28 23:59:00')), (Timestamp('2024-07-27 00:00:00'), Timestamp('2024-07-29 23:59:00')), (Timestamp('2024-07-28 00:00:00'), Timestamp('2024-07-30 23:59:00')), (Timestamp('2024-07-29 00:00:00'), Timestamp('2024-07-31 23:59:00')), (Timestamp('2024-07-30 00:00:00'), Timestamp('2024-08-01 23:59:00')), (Timestamp('2024-07-31 00:00:00'), Timestamp('2024-08-02 23:59:00')), (Timestamp('2024-08-01 00:00:00'), Timestamp('2024-08-03 23:59:00')), (Timestamp('2024-08-02 00:00:00'), Timestamp('2024-08-04 23:59:00')), (Timestamp('2024-08-03 00:00:00'), Timestamp('2024-08-05 23:59:00')), (Timestamp('2024-08-04 00:00:00'), Timestamp('2024-08-06 23:59:00')), (Timestamp('2024-08-05 00:00:00'), Timestamp('2024-08-07 23:59:00')), (Timestamp('2024-08-06 00:00:00'), Timestamp('2024-08-08 23:59:00')), (Timestamp('2024-08-07 00:00:00'), Timestamp('2024-08-09 23:59:00')), (Timestamp('2024-08-08 00:00:00'), Timestamp('2024-08-10 23:59:00')), (Timestamp('2024-08-09 00:00:00'), Timestamp('2024-08-11 23:59:00')), (Timestamp('2024-08-10 00:00:00'), Timestamp('2024-08-12 23:59:00')), (Timestamp('2024-08-11 00:00:00'), Timestamp('2024-08-13 23:59:00')), (Timestamp('2024-08-12 00:00:00'), Timestamp('2024-08-14 23:59:00')), (Timestamp('2024-08-13 00:00:00'), Timestamp('2024-08-15 23:59:00')), (Timestamp('2024-08-14 00:00:00'), Timestamp('2024-08-16 23:59:00')), (Timestamp('2024-08-15 00:00:00'), Timestamp('2024-08-17 23:59:00')), (Timestamp('2024-08-16 00:00:00'), Timestamp('2024-08-18 23:59:00')), (Timestamp('2024-08-17 00:00:00'), Timestamp('2024-08-19 23:59:00')), (Timestamp('2024-08-18 00:00:00'), Timestamp('2024-08-20 23:59:00')), (Timestamp('2024-08-19 00:00:00'), Timestamp('2024-08-21 23:59:00')), (Timestamp('2024-08-20 00:00:00'), Timestamp('2024-08-22 23:59:00')), (Timestamp('2024-08-21 00:00:00'), Timestamp('2024-08-23 23:59:00')), (Timestamp('2024-08-22 00:00:00'), Timestamp('2024-08-24 23:59:00')), (Timestamp('2024-08-23 00:00:00'), Timestamp('2024-08-25 23:59:00')), (Timestamp('2024-08-24 00:00:00'), Timestamp('2024-08-26 23:59:00')), (Timestamp('2024-08-25 00:00:00'), Timestamp('2024-08-27 23:59:00')), (Timestamp('2024-08-26 00:00:00'), Timestamp('2024-08-28 23:59:00')), (Timestamp('2024-08-27 00:00:00'), Timestamp('2024-08-29 23:59:00')), (Timestamp('2024-08-28 00:00:00'), Timestamp('2024-08-30 23:59:00')), (Timestamp('2024-08-29 00:00:00'), Timestamp('2024-08-31 23:59:00')), (Timestamp('2024-08-30 00:00:00'), Timestamp('2024-09-01 23:59:00')), (Timestamp('2024-08-31 00:00:00'), Timestamp('2024-09-02 23:59:00')), (Timestamp('2024-09-01 00:00:00'), Timestamp('2024-09-03 23:59:00')), (Timestamp('2024-09-02 00:00:00'), Timestamp('2024-09-04 23:59:00')), (Timestamp('2024-09-03 00:00:00'), Timestamp('2024-09-05 23:59:00')), (Timestamp('2024-09-04 00:00:00'), Timestamp('2024-09-06 23:59:00')), (Timestamp('2024-09-05 00:00:00'), Timestamp('2024-09-07 23:59:00')), (Timestamp('2024-09-06 00:00:00'), Timestamp('2024-09-08 23:59:00')), (Timestamp('2024-09-07 00:00:00'), Timestamp('2024-09-09 23:59:00')), (Timestamp('2024-09-08 00:00:00'), Timestamp('2024-09-10 23:59:00')), (Timestamp('2024-09-09 00:00:00'), Timestamp('2024-09-11 23:59:00')), (Timestamp('2024-09-10 00:00:00'), Timestamp('2024-09-12 23:59:00')), (Timestamp('2024-09-11 00:00:00'), Timestamp('2024-09-13 23:59:00')), (Timestamp('2024-09-12 00:00:00'), Timestamp('2024-09-14 23:59:00')), (Timestamp('2024-09-13 00:00:00'), Timestamp('2024-09-15 23:59:00')), (Timestamp('2024-09-14 00:00:00'), Timestamp('2024-09-16 23:59:00')), (Timestamp('2024-09-15 00:00:00'), Timestamp('2024-09-17 23:59:00')), (Timestamp('2024-09-16 00:00:00'), Timestamp('2024-09-18 23:59:00')), (Timestamp('2024-09-17 00:00:00'), Timestamp('2024-09-19 23:59:00')), (Timestamp('2024-09-18 00:00:00'), Timestamp('2024-09-20 23:59:00')), (Timestamp('2024-09-19 00:00:00'), Timestamp('2024-09-21 23:59:00')), (Timestamp('2024-09-20 00:00:00'), Timestamp('2024-09-22 23:59:00')), (Timestamp('2024-09-21 00:00:00'), Timestamp('2024-09-23 23:59:00')), (Timestamp('2024-09-22 00:00:00'), Timestamp('2024-09-24 23:59:00')), (Timestamp('2024-09-23 00:00:00'), Timestamp('2024-09-25 23:59:00')), (Timestamp('2024-09-24 00:00:00'), Timestamp('2024-09-26 23:59:00')), (Timestamp('2024-09-25 00:00:00'), Timestamp('2024-09-27 23:59:00')), (Timestamp('2024-09-26 00:00:00'), Timestamp('2024-09-28 23:59:00')), (Timestamp('2024-09-27 00:00:00'), Timestamp('2024-09-29 23:59:00')), (Timestamp('2024-09-28 00:00:00'), Timestamp('2024-09-30 23:59:00')), (Timestamp('2024-09-29 00:00:00'), Timestamp('2024-10-01 23:59:00')), (Timestamp('2024-09-30 00:00:00'), Timestamp('2024-10-02 23:59:00')), (Timestamp('2024-10-01 00:00:00'), Timestamp('2024-10-03 23:59:00')), (Timestamp('2024-10-02 00:00:00'), Timestamp('2024-10-04 23:59:00')), (Timestamp('2024-10-03 00:00:00'), Timestamp('2024-10-05 23:59:00')), (Timestamp('2024-10-04 00:00:00'), Timestamp('2024-10-06 23:59:00')), (Timestamp('2024-10-05 00:00:00'), Timestamp('2024-10-07 23:59:00')), (Timestamp('2024-10-06 00:00:00'), Timestamp('2024-10-08 23:59:00')), (Timestamp('2024-10-07 00:00:00'), Timestamp('2024-10-09 23:59:00')), (Timestamp('2024-10-08 00:00:00'), Timestamp('2024-10-10 23:59:00')), (Timestamp('2024-10-09 00:00:00'), Timestamp('2024-10-11 23:59:00')), (Timestamp('2024-10-10 00:00:00'), Timestamp('2024-10-12 23:59:00')), (Timestamp('2024-10-11 00:00:00'), Timestamp('2024-10-13 23:59:00')), (Timestamp('2024-10-12 00:00:00'), Timestamp('2024-10-14 23:59:00')), (Timestamp('2024-10-13 00:00:00'), Timestamp('2024-10-15 23:59:00')), (Timestamp('2024-10-14 00:00:00'), Timestamp('2024-10-16 23:59:00')), (Timestamp('2024-10-15 00:00:00'), Timestamp('2024-10-17 23:59:00')), (Timestamp('2024-10-16 00:00:00'), Timestamp('2024-10-18 23:59:00')), (Timestamp('2024-10-17 00:00:00'), Timestamp('2024-10-19 23:59:00')), (Timestamp('2024-10-18 00:00:00'), Timestamp('2024-10-20 23:59:00')), (Timestamp('2024-10-19 00:00:00'), Timestamp('2024-10-21 23:59:00')), (Timestamp('2024-10-20 00:00:00'), Timestamp('2024-10-22 23:59:00')), (Timestamp('2024-10-21 00:00:00'), Timestamp('2024-10-23 23:59:00')), (Timestamp('2024-10-22 00:00:00'), Timestamp('2024-10-24 23:59:00')), (Timestamp('2024-10-23 00:00:00'), Timestamp('2024-10-25 23:59:00')), (Timestamp('2024-10-24 00:00:00'), Timestamp('2024-10-26 23:59:00')), (Timestamp('2024-10-25 00:00:00'), Timestamp('2024-10-27 23:59:00')), (Timestamp('2024-10-26 00:00:00'), Timestamp('2024-10-28 23:59:00')), (Timestamp('2024-10-27 00:00:00'), Timestamp('2024-10-29 23:59:00')), (Timestamp('2024-10-28 00:00:00'), Timestamp('2024-10-30 23:59:00')), (Timestamp('2024-10-29 00:00:00'), Timestamp('2024-10-31 23:59:00')), (Timestamp('2024-10-30 00:00:00'), Timestamp('2024-11-01 23:59:00')), (Timestamp('2024-10-31 00:00:00'), Timestamp('2024-11-02 23:59:00')), (Timestamp('2024-11-01 00:00:00'), Timestamp('2024-11-03 23:59:00')), (Timestamp('2024-11-02 00:00:00'), Timestamp('2024-11-04 23:59:00')), (Timestamp('2024-11-03 00:00:00'), Timestamp('2024-11-05 23:59:00')), (Timestamp('2024-11-04 00:00:00'), Timestamp('2024-11-06 23:59:00')), (Timestamp('2024-11-05 00:00:00'), Timestamp('2024-11-07 23:59:00')), (Timestamp('2024-11-06 00:00:00'), Timestamp('2024-11-08 23:59:00')), (Timestamp('2024-11-07 00:00:00'), Timestamp('2024-11-09 23:59:00')), (Timestamp('2024-11-08 00:00:00'), Timestamp('2024-11-10 23:59:00')), (Timestamp('2024-11-09 00:00:00'), Timestamp('2024-11-11 23:59:00')), (Timestamp('2024-11-10 00:00:00'), Timestamp('2024-11-12 23:59:00')), (Timestamp('2024-11-11 00:00:00'), Timestamp('2024-11-13 23:59:00')), (Timestamp('2024-11-12 00:00:00'), Timestamp('2024-11-14 23:59:00')), (Timestamp('2024-11-13 00:00:00'), Timestamp('2024-11-15 23:59:00')), (Timestamp('2024-11-14 00:00:00'), Timestamp('2024-11-16 23:59:00')), (Timestamp('2024-11-15 00:00:00'), Timestamp('2024-11-17 23:59:00')), (Timestamp('2024-11-16 00:00:00'), Timestamp('2024-11-18 23:59:00')), (Timestamp('2024-11-17 00:00:00'), Timestamp('2024-11-19 23:59:00')), (Timestamp('2024-11-18 00:00:00'), Timestamp('2024-11-20 23:59:00')), (Timestamp('2024-11-19 00:00:00'), Timestamp('2024-11-21 23:59:00')), (Timestamp('2024-11-20 00:00:00'), Timestamp('2024-11-22 23:59:00')), (Timestamp('2024-11-21 00:00:00'), Timestamp('2024-11-23 23:59:00')), (Timestamp('2024-11-22 00:00:00'), Timestamp('2024-11-24 23:59:00')), (Timestamp('2024-11-23 00:00:00'), Timestamp('2024-11-25 23:59:00')), (Timestamp('2024-11-24 00:00:00'), Timestamp('2024-11-26 23:59:00')), (Timestamp('2024-11-25 00:00:00'), Timestamp('2024-11-27 23:59:00')), (Timestamp('2024-11-26 00:00:00'), Timestamp('2024-11-28 23:59:00')), (Timestamp('2024-11-27 00:00:00'), Timestamp('2024-11-29 23:59:00')), (Timestamp('2024-11-28 00:00:00'), Timestamp('2024-11-30 23:59:00')), (Timestamp('2024-11-29 00:00:00'), Timestamp('2024-12-01 23:59:00')), (Timestamp('2024-11-30 00:00:00'), Timestamp('2024-12-02 23:59:00')), (Timestamp('2024-12-01 00:00:00'), Timestamp('2024-12-03 23:59:00')), (Timestamp('2024-12-02 00:00:00'), Timestamp('2024-12-04 23:59:00')), (Timestamp('2024-12-03 00:00:00'), Timestamp('2024-12-05 23:59:00')), (Timestamp('2024-12-04 00:00:00'), Timestamp('2024-12-06 23:59:00')), (Timestamp('2024-12-05 00:00:00'), Timestamp('2024-12-07 23:59:00')), (Timestamp('2024-12-06 00:00:00'), Timestamp('2024-12-08 23:59:00')), (Timestamp('2024-12-07 00:00:00'), Timestamp('2024-12-09 23:59:00')), (Timestamp('2024-12-08 00:00:00'), Timestamp('2024-12-10 23:59:00')), (Timestamp('2024-12-09 00:00:00'), Timestamp('2024-12-11 23:59:00')), (Timestamp('2024-12-10 00:00:00'), Timestamp('2024-12-12 23:59:00')), (Timestamp('2024-12-11 00:00:00'), Timestamp('2024-12-13 23:59:00')), (Timestamp('2024-12-12 00:00:00'), Timestamp('2024-12-14 23:59:00')), (Timestamp('2024-12-13 00:00:00'), Timestamp('2024-12-15 23:59:00')), (Timestamp('2024-12-14 00:00:00'), Timestamp('2024-12-16 23:59:00')), (Timestamp('2024-12-15 00:00:00'), Timestamp('2024-12-17 23:59:00')), (Timestamp('2024-12-16 00:00:00'), Timestamp('2024-12-18 23:59:00')), (Timestamp('2024-12-17 00:00:00'), Timestamp('2024-12-19 23:59:00')), (Timestamp('2024-12-18 00:00:00'), Timestamp('2024-12-20 23:59:00')), (Timestamp('2024-12-19 00:00:00'), Timestamp('2024-12-21 23:59:00')), (Timestamp('2024-12-20 00:00:00'), Timestamp('2024-12-22 23:59:00')), (Timestamp('2024-12-21 00:00:00'), Timestamp('2024-12-23 23:59:00')), (Timestamp('2024-12-22 00:00:00'), Timestamp('2024-12-24 23:59:00')), (Timestamp('2024-12-23 00:00:00'), Timestamp('2024-12-25 23:59:00')), (Timestamp('2024-12-24 00:00:00'), Timestamp('2024-12-26 23:59:00')), (Timestamp('2024-12-25 00:00:00'), Timestamp('2024-12-27 23:59:00')), (Timestamp('2024-12-26 00:00:00'), Timestamp('2024-12-28 23:59:00')), (Timestamp('2024-12-27 00:00:00'), Timestamp('2024-12-29 23:59:00')), (Timestamp('2024-12-28 00:00:00'), Timestamp('2024-12-30 23:59:00')), (Timestamp('2024-12-29 00:00:00'), Timestamp('2024-12-31 23:59:00')), (Timestamp('2024-12-30 00:00:00'), Timestamp('2025-01-01 23:59:00')), (Timestamp('2024-12-31 00:00:00'), Timestamp('2025-01-02 23:59:00')), (Timestamp('2025-01-01 00:00:00'), Timestamp('2025-01-03 23:59:00')), (Timestamp('2025-01-02 00:00:00'), Timestamp('2025-01-04 23:59:00')), (Timestamp('2025-01-03 00:00:00'), Timestamp('2025-01-05 23:59:00')), (Timestamp('2025-01-04 00:00:00'), Timestamp('2025-01-06 23:59:00')), (Timestamp('2025-01-05 00:00:00'), Timestamp('2025-01-07 23:59:00')), (Timestamp('2025-01-06 00:00:00'), Timestamp('2025-01-08 23:59:00')), (Timestamp('2025-01-07 00:00:00'), Timestamp('2025-01-09 23:59:00')), (Timestamp('2025-01-08 00:00:00'), Timestamp('2025-01-10 23:59:00')), (Timestamp('2025-01-09 00:00:00'), Timestamp('2025-01-11 23:59:00')), (Timestamp('2025-01-10 00:00:00'), Timestamp('2025-01-12 23:59:00')), (Timestamp('2025-01-11 00:00:00'), Timestamp('2025-01-13 23:59:00')), (Timestamp('2025-01-12 00:00:00'), Timestamp('2025-01-14 23:59:00')), (Timestamp('2025-01-13 00:00:00'), Timestamp('2025-01-15 23:59:00')), (Timestamp('2025-01-14 00:00:00'), Timestamp('2025-01-16 23:59:00')), (Timestamp('2025-01-15 00:00:00'), Timestamp('2025-01-17 23:59:00')), (Timestamp('2025-01-16 00:00:00'), Timestamp('2025-01-18 23:59:00')), (Timestamp('2025-01-17 00:00:00'), Timestamp('2025-01-19 23:59:00')), (Timestamp('2025-01-18 00:00:00'), Timestamp('2025-01-20 23:59:00')), (Timestamp('2025-01-19 00:00:00'), Timestamp('2025-01-21 23:59:00')), (Timestamp('2025-01-20 00:00:00'), Timestamp('2025-01-22 23:59:00')), (Timestamp('2025-01-21 00:00:00'), Timestamp('2025-01-23 23:59:00')), (Timestamp('2025-01-22 00:00:00'), Timestamp('2025-01-24 23:59:00')), (Timestamp('2025-01-23 00:00:00'), Timestamp('2025-01-25 23:59:00')), (Timestamp('2025-01-24 00:00:00'), Timestamp('2025-01-26 23:59:00')), (Timestamp('2025-01-25 00:00:00'), Timestamp('2025-01-27 23:59:00')), (Timestamp('2025-01-26 00:00:00'), Timestamp('2025-01-28 23:59:00')), (Timestamp('2025-01-27 00:00:00'), Timestamp('2025-01-29 23:59:00')), (Timestamp('2025-01-28 00:00:00'), Timestamp('2025-01-30 23:59:00')), (Timestamp('2025-01-29 00:00:00'), Timestamp('2025-01-31 23:59:00')), (Timestamp('2025-01-30 00:00:00'), Timestamp('2025-02-01 23:59:00')), (Timestamp('2025-01-31 00:00:00'), Timestamp('2025-02-02 23:59:00')), (Timestamp('2025-02-01 00:00:00'), Timestamp('2025-02-03 23:59:00')), (Timestamp('2025-02-02 00:00:00'), Timestamp('2025-02-04 23:59:00')), (Timestamp('2025-02-03 00:00:00'), Timestamp('2025-02-05 23:59:00')), (Timestamp('2025-02-04 00:00:00'), Timestamp('2025-02-06 23:59:00')), (Timestamp('2025-02-05 00:00:00'), Timestamp('2025-02-07 23:59:00')), (Timestamp('2025-02-06 00:00:00'), Timestamp('2025-02-08 23:59:00')), (Timestamp('2025-02-07 00:00:00'), Timestamp('2025-02-09 23:59:00')), (Timestamp('2025-02-08 00:00:00'), Timestamp('2025-02-10 23:59:00')), (Timestamp('2025-02-09 00:00:00'), Timestamp('2025-02-11 23:59:00')), (Timestamp('2025-02-10 00:00:00'), Timestamp('2025-02-12 23:59:00')), (Timestamp('2025-02-11 00:00:00'), Timestamp('2025-02-13 23:59:00')), (Timestamp('2025-02-12 00:00:00'), Timestamp('2025-02-14 23:59:00')), (Timestamp('2025-02-13 00:00:00'), Timestamp('2025-02-15 23:59:00')), (Timestamp('2025-02-14 00:00:00'), Timestamp('2025-02-16 23:59:00')), (Timestamp('2025-02-15 00:00:00'), Timestamp('2025-02-17 23:59:00')), (Timestamp('2025-02-16 00:00:00'), Timestamp('2025-02-18 23:59:00')), (Timestamp('2025-02-17 00:00:00'), Timestamp('2025-02-19 23:59:00')), (Timestamp('2025-02-18 00:00:00'), Timestamp('2025-02-20 23:59:00')), (Timestamp('2025-02-19 00:00:00'), Timestamp('2025-02-21 23:59:00')), (Timestamp('2025-02-20 00:00:00'), Timestamp('2025-02-22 23:59:00')), (Timestamp('2025-02-21 00:00:00'), Timestamp('2025-02-23 23:59:00')), (Timestamp('2025-02-22 00:00:00'), Timestamp('2025-02-24 23:59:00')), (Timestamp('2025-02-23 00:00:00'), Timestamp('2025-02-25 23:59:00')), (Timestamp('2025-02-24 00:00:00'), Timestamp('2025-02-26 23:59:00')), (Timestamp('2025-02-25 00:00:00'), Timestamp('2025-02-27 23:59:00')), (Timestamp('2025-02-26 00:00:00'), Timestamp('2025-02-28 23:59:00')), (Timestamp('2025-02-27 00:00:00'), Timestamp('2025-03-01 23:59:00')), (Timestamp('2025-02-28 00:00:00'), Timestamp('2025-03-02 23:59:00')), (Timestamp('2025-03-01 00:00:00'), Timestamp('2025-03-03 23:59:00')), (Timestamp('2025-03-02 00:00:00'), Timestamp('2025-03-04 23:59:00')), (Timestamp('2025-03-03 00:00:00'), Timestamp('2025-03-05 23:59:00')), (Timestamp('2025-03-04 00:00:00'), Timestamp('2025-03-06 23:59:00')), (Timestamp('2025-03-05 00:00:00'), Timestamp('2025-03-07 23:59:00')), (Timestamp('2025-03-06 00:00:00'), Timestamp('2025-03-08 23:59:00')), (Timestamp('2025-03-07 00:00:00'), Timestamp('2025-03-09 23:59:00')), (Timestamp('2025-03-08 00:00:00'), Timestamp('2025-03-10 23:59:00')), (Timestamp('2025-03-09 00:00:00'), Timestamp('2025-03-11 23:59:00')), (Timestamp('2025-03-10 00:00:00'), Timestamp('2025-03-12 23:59:00')), (Timestamp('2025-03-11 00:00:00'), Timestamp('2025-03-13 23:59:00')), (Timestamp('2025-03-12 00:00:00'), Timestamp('2025-03-14 23:59:00')), (Timestamp('2025-03-13 00:00:00'), Timestamp('2025-03-15 23:59:00')), (Timestamp('2025-03-14 00:00:00'), Timestamp('2025-03-16 23:59:00')), (Timestamp('2025-03-15 00:00:00'), Timestamp('2025-03-17 23:59:00')), (Timestamp('2025-03-16 00:00:00'), Timestamp('2025-03-18 23:59:00')), (Timestamp('2025-03-17 00:00:00'), Timestamp('2025-03-19 23:59:00')), (Timestamp('2025-03-18 00:00:00'), Timestamp('2025-03-20 23:59:00')), (Timestamp('2025-03-19 00:00:00'), Timestamp('2025-03-21 23:59:00')), (Timestamp('2025-03-20 00:00:00'), Timestamp('2025-03-22 23:59:00')), (Timestamp('2025-03-21 00:00:00'), Timestamp('2025-03-23 23:59:00')), (Timestamp('2025-03-22 00:00:00'), Timestamp('2025-03-24 23:59:00')), (Timestamp('2025-03-23 00:00:00'), Timestamp('2025-03-25 23:59:00')), (Timestamp('2025-03-24 00:00:00'), Timestamp('2025-03-26 23:59:00')), (Timestamp('2025-03-25 00:00:00'), Timestamp('2025-03-27 23:59:00')), (Timestamp('2025-03-26 00:00:00'), Timestamp('2025-03-28 23:59:00')), (Timestamp('2025-03-27 00:00:00'), Timestamp('2025-03-29 23:59:00')), (Timestamp('2025-03-28 00:00:00'), Timestamp('2025-03-30 23:59:00')), (Timestamp('2025-03-29 00:00:00'), Timestamp('2025-03-31 23:59:00')), (Timestamp('2025-03-30 00:00:00'), Timestamp('2025-04-01 23:59:00')), (Timestamp('2025-03-31 00:00:00'), Timestamp('2025-04-02 23:59:00')), (Timestamp('2025-04-01 00:00:00'), Timestamp('2025-04-03 23:59:00')), (Timestamp('2025-04-02 00:00:00'), Timestamp('2025-04-04 23:59:00')), (Timestamp('2025-04-03 00:00:00'), Timestamp('2025-04-05 23:59:00')), (Timestamp('2025-04-04 00:00:00'), Timestamp('2025-04-06 23:59:00')), (Timestamp('2025-04-05 00:00:00'), Timestamp('2025-04-07 23:59:00')), (Timestamp('2025-04-06 00:00:00'), Timestamp('2025-04-08 23:59:00')), (Timestamp('2025-04-07 00:00:00'), Timestamp('2025-04-09 23:59:00')), (Timestamp('2025-04-08 00:00:00'), Timestamp('2025-04-10 23:59:00')), (Timestamp('2025-04-09 00:00:00'), Timestamp('2025-04-11 23:59:00')), (Timestamp('2025-04-10 00:00:00'), Timestamp('2025-04-12 23:59:00')), (Timestamp('2025-04-11 00:00:00'), Timestamp('2025-04-13 23:59:00')), (Timestamp('2025-04-12 00:00:00'), Timestamp('2025-04-14 23:59:00')), (Timestamp('2025-04-13 00:00:00'), Timestamp('2025-04-15 23:59:00')), (Timestamp('2025-04-14 00:00:00'), Timestamp('2025-04-16 23:59:00')), (Timestamp('2025-04-15 00:00:00'), Timestamp('2025-04-17 23:59:00')), (Timestamp('2025-04-16 00:00:00'), Timestamp('2025-04-18 23:59:00')), (Timestamp('2025-04-17 00:00:00'), Timestamp('2025-04-19 23:59:00')), (Timestamp('2025-04-18 00:00:00'), Timestamp('2025-04-20 23:59:00')), (Timestamp('2025-04-19 00:00:00'), Timestamp('2025-04-21 23:59:00')), (Timestamp('2025-04-20 00:00:00'), Timestamp('2025-04-22 23:59:00')), (Timestamp('2025-04-21 00:00:00'), Timestamp('2025-04-23 23:59:00')), (Timestamp('2025-04-22 00:00:00'), Timestamp('2025-04-24 23:59:00')), (Timestamp('2025-04-23 00:00:00'), Timestamp('2025-04-25 23:59:00')), (Timestamp('2025-04-24 00:00:00'), Timestamp('2025-04-26 23:59:00')), (Timestamp('2025-04-25 00:00:00'), Timestamp('2025-04-27 23:59:00')), (Timestamp('2025-04-26 00:00:00'), Timestamp('2025-04-28 23:59:00')), (Timestamp('2025-04-27 00:00:00'), Timestamp('2025-04-29 23:59:00')), (Timestamp('2025-04-28 00:00:00'), Timestamp('2025-04-30 23:59:00'))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pairs_per_window.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f54336a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('AVAX', 'ETC'),\n",
       "  0.9741800335098781,\n",
       "  1.2010378687797196,\n",
       "  -0.38587014779241713,\n",
       "  0.038911554622404136),\n",
       " (('XLM', 'XRP'),\n",
       "  0.9594458707339523,\n",
       "  0.7275602589976646,\n",
       "  -1.7309388665873797,\n",
       "  0.00394629244133999),\n",
       " (('ETC', 'ETH'),\n",
       "  0.9444983486845285,\n",
       "  1.2561219068345864,\n",
       "  -6.806165235426221,\n",
       "  0.046266802293490464),\n",
       " (('ADA', 'XRP'),\n",
       "  0.9427801627025159,\n",
       "  1.0219154351046322,\n",
       "  -0.11805425039149098,\n",
       "  0.0168253001015466),\n",
       " (('ADA', 'LTC'),\n",
       "  0.9414120954592604,\n",
       "  1.2107959157928638,\n",
       "  -6.099804334369608,\n",
       "  0.04899689205298267)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pairs_per_window[(pd.Timestamp('2024-05-01 00:00:00'), pd.Timestamp('2024-05-03 23:59:00'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d01798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column AAVE_close is complete\n",
      "Column ADA_close is complete\n",
      "Column APT_close is complete\n",
      "Column ARB_close is complete\n",
      "Column ATOM_close is complete\n",
      "Column AVAX_close is complete\n",
      "Column BCH_close is complete\n",
      "Column BNB_close is complete\n",
      "Column BTC_close is complete\n",
      "Column DOGE_close is complete\n",
      "Column DOT_close is complete\n",
      "Column ENA_close is complete\n",
      "Column ETC_close is complete\n",
      "Column ETH_close is complete\n",
      "Column HBAR_close is complete\n",
      "Column LINK_close is complete\n",
      "Column LTC_close is complete\n",
      "Column NEAR_close is complete\n",
      "Column SUI_close is complete\n",
      "Column TON_close is complete\n",
      "Column TRX_close is complete\n",
      "Column UNI_close is complete\n",
      "Column WLD_close is complete\n",
      "Column XLM_close is complete\n",
      "Column XRP_close is complete\n"
     ]
    }
   ],
   "source": [
    "# check if there are na in close prices for full_df\n",
    "for col in full_df.columns:\n",
    "    if col.endswith(\"_close\"):\n",
    "        if full_df[col].isna().any():\n",
    "            print(f\"Column {col} has NaN values\")\n",
    "        else:\n",
    "            print(f\"Column {col} is complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c0c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
